# pytorch  
  
**pytorch와 tencerflow의 차이**  
동적신경망과 정적신경망
  
**GPU 와 CPU의 차이**
GPU는 병렬연산의 최적화  

22년 말 chat-gpt의 등장으로 구글의 성장이 주춤  

touch.autograd: 자동 미분 패키지  
torch.nn: 
touch.multiprocessing  
touch.utills  

인텔과 엔비디아  
cpu 다루는 api는 인텔
gpu 다루는 api는 cuda
cuda ai 라이브러리 쉽게쓰게 해줌  

파이토치 아키텍처  

offset: 텐서에서 첫 번째 요소가 스토리지에 저장된 미션  
stride:  
conda create -n torch_book python = 3.9.0  

tencer는 새로운 자료형  

view를 쓰면 tensor의 shape을 바꿀 수 있음  
__-__이런것은 내부함수

합성곱 신경망 구조<br/><br/>
⚫ 즉, 합성곱층을 요약하면 다음과 같음<br/>
입력 데이터: W1×H1×D1 (W1<br/>
: 가로, ×H1<br/>
: 세로, ×D1<br/>
: 채널 또는 깊이)<br/><br/>
하이퍼파라미터<br/>
• 필터 개수: K<br/>
• 필터 크기: F<br/>
• 스트라이드: S<br/>
• 패딩: P<br/><br/>
출력 데이터<br/>
• W2 = (W1-F+2P)/S+1<br/>
• H2 = (H1-F+2P)/S+1
• D2 = K<br/>  

### 전이학습  
전이학습(Transfer learning)은 어떤 목적을 이루기 위해 학습된 모델을 다른 작업에 이용하는 것  
즉 모델의 지식을 다른 문제에 이용하는 것으로 볼 수 있습니다.  

**특성-추출 기법**
opencv깔기  
## LeNet-5  <br/>
② _ _call_ _ 함수는 클래스를 호출할 수 있도록 하는 메서드<br/>
⚫ _ _init_ _은 인스턴스 초기화를 위해 사용한다면 _ _ call_ _은 인스턴스가 호출되었을 때<br/>
실행
⚫ 즉, 클래스에 _ _call_ _ 함수가 있을 경우 클래스 객체 자체를 호출하면 _ _call_ _ 함수의<br/>
리턴(return) 값이 반환<br/>
⚫ 이미지가 위치한 디렉터리에서 데이터를 불러온 후 훈련용으로 400개의 이미지, <br/>
검증용으로 92개의 이미지, 테스트용으로 열 개의 이미지를 사용<br/>
피쳐맵은 줄어들고 채널은 늘어나는 구조  <br/>

maxpool2d는 보통 2이다
커널 사이즈를 조정하는게 낫다
stride를 늘리면 패딩사이즈가 확줄음

### VGG-NET  
합성곱을 많이씀  
진정한 딥러  

이미지 전체를 받아서 넣는다 피쳐맵에서 뽑느다
왜? 너무 많아서 피쳐맵으로 뽑는것이 좋음
CCNN 양방향 풀리커넥티드 한쪽에서는 있냐 없냐 한쪽에서는 좌표를 
그리드를 만들어서 각점으로 16개나 4개를 만들어서 

yolo는 한층에서만 했지만 신뢰도도 평가야하여 보완함

정확도는 faster r-cnn 속도는 yolo
