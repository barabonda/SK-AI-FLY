{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "958ae5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10.1.1 희소표현(Sparse Representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d93e9e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "class2=pd.read_csv(\"data/class2.csv\")\n",
    "\n",
    "from sklearn import preprocessing \n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "onehot_encoder = preprocessing.OneHotEncoder()\n",
    "\n",
    "train_x = label_encoder.fit_transform(class2['class2'])\n",
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6af2eeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10.1.2 횟수기반 임베딩\n",
    "#Counter Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5298928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'this': 13,\n",
       " 'is': 7,\n",
       " 'last': 8,\n",
       " 'chance': 2,\n",
       " 'and': 0,\n",
       " 'if': 6,\n",
       " 'you': 15,\n",
       " 'do': 3,\n",
       " 'not': 10,\n",
       " 'have': 5,\n",
       " 'will': 14,\n",
       " 'never': 9,\n",
       " 'get': 4,\n",
       " 'any': 1,\n",
       " 'one': 11,\n",
       " 'please': 12}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = [\n",
    "    'This is last chance.',\n",
    "    'and if you do not have this chance.',\n",
    "    'you will never get any chance.',\n",
    "    'will you do get this one?',\n",
    "    'please, get this chance',\n",
    "]\n",
    "vect = CountVectorizer()\n",
    "vect.fit(corpus)\n",
    "vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cda3fe3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.transform(['you will never get any chance.']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b305aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'last': 6,\n",
       " 'chance': 1,\n",
       " 'if': 5,\n",
       " 'you': 11,\n",
       " 'do': 2,\n",
       " 'not': 8,\n",
       " 'have': 4,\n",
       " 'will': 10,\n",
       " 'never': 7,\n",
       " 'get': 3,\n",
       " 'any': 0,\n",
       " 'one': 9}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer(stop_words=[\"and\", \"is\", \"please\", \"this\"]).fit(corpus)\n",
    "vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d212c4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fea52e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "유사도를 위한 3 x 3 matrix를 만들었습니다.\n",
      "[[1.       0.224325 0.      ]\n",
      " [0.224325 1.       0.      ]\n",
      " [0.       0.       1.      ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "doc = ['I like machine learning', 'I love deep learning', 'I run everyday']\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df=1)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(doc)\n",
    "doc_distance = (tfidf_matrix * tfidf_matrix.T)\n",
    "print ('유사도를 위한', str(doc_distance.get_shape()[0]), 'x', str(doc_distance.get_shape()[1]), 'matrix를 만들었습니다.')\n",
    "print(doc_distance.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52460393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\2022-pc(t)-10\\.conda\\envs\\torch_book\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\2022-pc(t)-10\\.conda\\envs\\torch_book\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\2022-pc(t)-10\\.conda\\envs\\torch_book\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\2022-pc(t)-10\\.conda\\envs\\torch_book\\lib\\site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in c:\\users\\2022-pc(t)-10\\.conda\\envs\\torch_book\\lib\\site-packages (from nltk) (4.65.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\2022-pc(t)-10\\.conda\\envs\\torch_book\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "#10.1.3 예측기반 임베딩\n",
    "# Word2Vec\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87e22753-f695-462a-a142-2b28b17a382d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\2022-PC(T)-10\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13f70276-c7da-4929-b720-a1d207cf8db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gensim in c:\\programdata\\anaconda3\\lib\\site-packages (4.3.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from gensim) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from gensim) (1.11.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: FuzzyTM>=0.4.0 in c:\\users\\2022-pc(t)-10\\appdata\\roaming\\python\\python311\\site-packages (from gensim) (2.0.5)\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (from FuzzyTM>=0.4.0->gensim) (2.0.3)\n",
      "Requirement already satisfied: pyfume in c:\\users\\2022-pc(t)-10\\appdata\\roaming\\python\\python311\\site-packages (from FuzzyTM>=0.4.0->gensim) (0.2.25)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2023.3)\n",
      "Requirement already satisfied: simpful in c:\\users\\2022-pc(t)-10\\appdata\\roaming\\python\\python311\\site-packages (from pyfume->FuzzyTM>=0.4.0->gensim) (2.11.1)\n",
      "Requirement already satisfied: fst-pso in c:\\users\\2022-pc(t)-10\\appdata\\roaming\\python\\python311\\site-packages (from pyfume->FuzzyTM>=0.4.0->gensim) (1.8.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->FuzzyTM>=0.4.0->gensim) (1.16.0)\n",
      "Requirement already satisfied: miniful in c:\\users\\2022-pc(t)-10\\appdata\\roaming\\python\\python311\\site-packages (from fst-pso->pyfume->FuzzyTM>=0.4.0->gensim) (0.0.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5dd8958f-f872-4516-9260-13f3216d339f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['once',\n",
       "  'upon',\n",
       "  'a',\n",
       "  'time',\n",
       "  'in',\n",
       "  'london',\n",
       "  ',',\n",
       "  'the',\n",
       "  'darlings',\n",
       "  'went',\n",
       "  'out',\n",
       "  'to',\n",
       "  'a',\n",
       "  'dinner',\n",
       "  'party',\n",
       "  'leaving',\n",
       "  'their',\n",
       "  'three',\n",
       "  'children',\n",
       "  'wendy',\n",
       "  ',',\n",
       "  'jhon',\n",
       "  ',',\n",
       "  'and',\n",
       "  'michael',\n",
       "  'at',\n",
       "  'home',\n",
       "  '.'],\n",
       " ['after',\n",
       "  'wendy',\n",
       "  'had',\n",
       "  'tucked',\n",
       "  'her',\n",
       "  'younger',\n",
       "  'brothers',\n",
       "  'jhon',\n",
       "  'and',\n",
       "  'michael',\n",
       "  'to',\n",
       "  'bed',\n",
       "  ',',\n",
       "  'she',\n",
       "  'went',\n",
       "  'to',\n",
       "  'read',\n",
       "  'a',\n",
       "  'book',\n",
       "  '.'],\n",
       " ['she', 'heard', 'a', 'boy', 'sobbing', 'outside', 'her', 'window', '.'],\n",
       " ['he', 'was', 'flying', '.'],\n",
       " ['there', 'was', 'little', 'fairy', 'fluttering', 'around', 'him', '.'],\n",
       " ['wendy', 'opened', 'the', 'window', 'to', 'talk', 'to', 'him', '.'],\n",
       " ['“', 'hello', '!'],\n",
       " ['who', 'are', 'you', '?'],\n",
       " ['why', 'are', 'you', 'crying', '”', ',', 'wendy', 'asked', 'him', '.'],\n",
       " ['“', 'my', 'name', 'is', 'peter', 'pan', '.'],\n",
       " ['my',\n",
       "  'shadow',\n",
       "  'wouldn',\n",
       "  '’',\n",
       "  't',\n",
       "  'stock',\n",
       "  'to',\n",
       "  'me.',\n",
       "  '”',\n",
       "  ',',\n",
       "  'he',\n",
       "  'replied',\n",
       "  '.'],\n",
       " ['she', 'asked', 'him', 'to', 'come', 'in', '.'],\n",
       " ['peter', 'agreed', 'and', 'came', 'inside', 'the', 'room', '.'],\n",
       " ['wendy',\n",
       "  'took',\n",
       "  'his',\n",
       "  'shadow',\n",
       "  'and',\n",
       "  'sewed',\n",
       "  'it',\n",
       "  'to',\n",
       "  'his',\n",
       "  'shoe',\n",
       "  'tips',\n",
       "  '.'],\n",
       " ['now',\n",
       "  'his',\n",
       "  'shadow',\n",
       "  'followed',\n",
       "  'him',\n",
       "  'wherever',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'went',\n",
       "  '!'],\n",
       " ['he',\n",
       "  'was',\n",
       "  'delighted',\n",
       "  'and',\n",
       "  'asked',\n",
       "  'wendy',\n",
       "  '“',\n",
       "  'why',\n",
       "  'don',\n",
       "  '’',\n",
       "  't',\n",
       "  'you',\n",
       "  'come',\n",
       "  'with',\n",
       "  'me',\n",
       "  'to',\n",
       "  'my',\n",
       "  'home',\n",
       "  '.'],\n",
       " ['the', 'neverland', '.'],\n",
       " ['i',\n",
       "  'lived',\n",
       "  'there',\n",
       "  'with',\n",
       "  'my',\n",
       "  'fairy',\n",
       "  'tinker',\n",
       "  'bell.',\n",
       "  '”',\n",
       "  'wendy',\n",
       "  '?'],\n",
       " ['“', 'oh', '!'],\n",
       " ['what', 'a', 'wonderful', 'idea', '!'],\n",
       " ['let', 'me', 'wake', 'up', 'john', 'and', 'micheal', 'too', '.'],\n",
       " ['could', 'you', 'teach', 'us', 'how', 'to', 'fly', '?', '”', '.'],\n",
       " ['“', 'yes', '!'],\n",
       " ['of', 'course', '!'],\n",
       " ['get',\n",
       "  'them',\n",
       "  'we',\n",
       "  'will',\n",
       "  'all',\n",
       "  'fly',\n",
       "  'together.',\n",
       "  '”',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'replied',\n",
       "  'and',\n",
       "  'so',\n",
       "  'it',\n",
       "  'was',\n",
       "  '.'],\n",
       " ['five',\n",
       "  'little',\n",
       "  'figures',\n",
       "  'flew',\n",
       "  'out',\n",
       "  'of',\n",
       "  'the',\n",
       "  'window',\n",
       "  'of',\n",
       "  'the',\n",
       "  'darlings',\n",
       "  'and',\n",
       "  'headed',\n",
       "  'towards',\n",
       "  'neverland',\n",
       "  '.'],\n",
       " ['as',\n",
       "  'they',\n",
       "  'flew',\n",
       "  'over',\n",
       "  'the',\n",
       "  'island',\n",
       "  ',',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'told',\n",
       "  'the',\n",
       "  'children',\n",
       "  'more',\n",
       "  'about',\n",
       "  'his',\n",
       "  'homeland',\n",
       "  '.'],\n",
       " ['“',\n",
       "  'all',\n",
       "  'the',\n",
       "  'children',\n",
       "  'who',\n",
       "  'get',\n",
       "  'lost',\n",
       "  'come',\n",
       "  'and',\n",
       "  'stay',\n",
       "  'with',\n",
       "  'tinker',\n",
       "  'bell',\n",
       "  'and',\n",
       "  'me',\n",
       "  ',',\n",
       "  '”',\n",
       "  'peter',\n",
       "  'told',\n",
       "  'them',\n",
       "  '.'],\n",
       " ['the', 'indians', 'also', 'live', 'in', 'neverland', '.'],\n",
       " ['the',\n",
       "  'mermaids',\n",
       "  'live',\n",
       "  'in',\n",
       "  'the',\n",
       "  'lagoon',\n",
       "  'around',\n",
       "  'the',\n",
       "  'island',\n",
       "  '.'],\n",
       " ['and',\n",
       "  'a',\n",
       "  'very',\n",
       "  'mean',\n",
       "  'pirate',\n",
       "  'called',\n",
       "  'captain',\n",
       "  'hook',\n",
       "  'keeps',\n",
       "  'troubling',\n",
       "  'everyone',\n",
       "  '.'],\n",
       " ['“', 'crocodile', 'bit', 'his', 'one', 'arm', '.'],\n",
       " ['so',\n",
       "  'the',\n",
       "  'captain',\n",
       "  'had',\n",
       "  'to',\n",
       "  'put',\n",
       "  'a',\n",
       "  'hook',\n",
       "  'in',\n",
       "  'its',\n",
       "  'place',\n",
       "  '.'],\n",
       " ['since', 'then', 'he', 'is', 'afraid', 'of', 'crocodiles', '.'],\n",
       " ['and', 'rightly', 'so', '!'],\n",
       " ['if',\n",
       "  'the',\n",
       "  'crocodile',\n",
       "  'ever',\n",
       "  'found',\n",
       "  'captain',\n",
       "  'hook',\n",
       "  'it',\n",
       "  'will',\n",
       "  'eat',\n",
       "  'up',\n",
       "  'the',\n",
       "  'rest',\n",
       "  'of',\n",
       "  'it',\n",
       "  'couldn',\n",
       "  '’',\n",
       "  't',\n",
       "  'eat',\n",
       "  'last',\n",
       "  'time.',\n",
       "  '”',\n",
       "  'peter',\n",
       "  'told',\n",
       "  'them',\n",
       "  '.'],\n",
       " ['soon', 'they', 'landed', 'on', 'the', 'island', '.'],\n",
       " ['and',\n",
       "  'to',\n",
       "  'the',\n",
       "  'surprise',\n",
       "  'of',\n",
       "  'wendy',\n",
       "  ',',\n",
       "  'jhon',\n",
       "  'and',\n",
       "  'michael',\n",
       "  ',',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'let',\n",
       "  'them',\n",
       "  'in',\n",
       "  'through',\n",
       "  'a',\n",
       "  'small',\n",
       "  'opening',\n",
       "  'in',\n",
       "  'a',\n",
       "  'tree',\n",
       "  '.'],\n",
       " ['inside',\n",
       "  'the',\n",
       "  'tree',\n",
       "  'was',\n",
       "  'a',\n",
       "  'large',\n",
       "  'room',\n",
       "  'with',\n",
       "  'children',\n",
       "  'inside',\n",
       "  'it',\n",
       "  '.'],\n",
       " ['somewhere',\n",
       "  'huddled',\n",
       "  'by',\n",
       "  'the',\n",
       "  'fire',\n",
       "  'in',\n",
       "  'the',\n",
       "  'corner',\n",
       "  'and',\n",
       "  'somewhere',\n",
       "  'playing',\n",
       "  'amongst',\n",
       "  'themselves',\n",
       "  '.'],\n",
       " ['their',\n",
       "  'faces',\n",
       "  'lit',\n",
       "  'up',\n",
       "  'when',\n",
       "  'they',\n",
       "  'saw',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  ',',\n",
       "  'tinker',\n",
       "  'bell',\n",
       "  ',',\n",
       "  'and',\n",
       "  'their',\n",
       "  'guests',\n",
       "  '.'],\n",
       " ['“', 'hello', 'everyone', '.'],\n",
       " ['this', 'is', 'wendy', ',', 'jhon', ',', 'and', 'michael', '.'],\n",
       " ['they',\n",
       "  'will',\n",
       "  'be',\n",
       "  'staying',\n",
       "  'with',\n",
       "  'us',\n",
       "  'from',\n",
       "  'now',\n",
       "  'on.',\n",
       "  '”',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'introduced',\n",
       "  'them',\n",
       "  'to',\n",
       "  'all',\n",
       "  'children',\n",
       "  '.'],\n",
       " ['children', 'welcomed', 'wendy', ',', 'jhon', ',', 'and', 'michael', '.'],\n",
       " ['a', 'few', 'days', 'passed', '.'],\n",
       " ['and', 'they', 'settled', 'into', 'a', 'routine', '.'],\n",
       " ['wendy',\n",
       "  'would',\n",
       "  'take',\n",
       "  'care',\n",
       "  'of',\n",
       "  'all',\n",
       "  'the',\n",
       "  'children',\n",
       "  'in',\n",
       "  'the',\n",
       "  'day',\n",
       "  'and',\n",
       "  'would',\n",
       "  'go',\n",
       "  'out',\n",
       "  'with',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'and',\n",
       "  'her',\n",
       "  'brothers',\n",
       "  'in',\n",
       "  'the',\n",
       "  'evening',\n",
       "  'to',\n",
       "  'learn',\n",
       "  'about',\n",
       "  'the',\n",
       "  'island',\n",
       "  '.'],\n",
       " ['she',\n",
       "  'would',\n",
       "  'cook',\n",
       "  'for',\n",
       "  'them',\n",
       "  'and',\n",
       "  'stitch',\n",
       "  'new',\n",
       "  'clothes',\n",
       "  'for',\n",
       "  'them',\n",
       "  '.'],\n",
       " ['he',\n",
       "  'even',\n",
       "  'made',\n",
       "  'a',\n",
       "  'lovely',\n",
       "  'new',\n",
       "  'dress',\n",
       "  'for',\n",
       "  'tinker',\n",
       "  'bell',\n",
       "  '.'],\n",
       " ['one',\n",
       "  'evening',\n",
       "  ',',\n",
       "  'as',\n",
       "  'they',\n",
       "  'were',\n",
       "  'out',\n",
       "  'exploring',\n",
       "  'the',\n",
       "  'island',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'warned',\n",
       "  'everyone',\n",
       "  'and',\n",
       "  'said',\n",
       "  ',',\n",
       "  '“',\n",
       "  'hide',\n",
       "  '!'],\n",
       " ['hide', '!'],\n",
       " ['pirates', '!'],\n",
       " ['and',\n",
       "  'they',\n",
       "  'have',\n",
       "  'kidnapped',\n",
       "  'the',\n",
       "  'indian',\n",
       "  'princess',\n",
       "  'tiger',\n",
       "  'lily',\n",
       "  '.'],\n",
       " ['they',\n",
       "  'have',\n",
       "  'kept',\n",
       "  'her',\n",
       "  'there',\n",
       "  ',',\n",
       "  'tied',\n",
       "  'up',\n",
       "  'by',\n",
       "  'the',\n",
       "  'rocks',\n",
       "  ',',\n",
       "  'near',\n",
       "  'the',\n",
       "  'water.',\n",
       "  '”',\n",
       "  'peter',\n",
       "  'was',\n",
       "  'afraid',\n",
       "  'and',\n",
       "  'the',\n",
       "  'princess',\n",
       "  'would',\n",
       "  'drown',\n",
       "  ',',\n",
       "  'is',\n",
       "  'she',\n",
       "  'fell',\n",
       "  'into',\n",
       "  'the',\n",
       "  'water',\n",
       "  '.'],\n",
       " ['so',\n",
       "  ',',\n",
       "  'in',\n",
       "  'a',\n",
       "  'voice',\n",
       "  'that',\n",
       "  'sounded',\n",
       "  'like',\n",
       "  'captain',\n",
       "  'hook',\n",
       "  ',',\n",
       "  'he',\n",
       "  'shouted',\n",
       "  'instructions',\n",
       "  'to',\n",
       "  'the',\n",
       "  'pirates',\n",
       "  'who',\n",
       "  'guarded',\n",
       "  'her',\n",
       "  ',',\n",
       "  '“',\n",
       "  'you',\n",
       "  'fools',\n",
       "  '!'],\n",
       " ['let', 'her', 'go', 'at', 'once', '!'],\n",
       " ['do',\n",
       "  'it',\n",
       "  'before',\n",
       "  'i',\n",
       "  'come',\n",
       "  'there',\n",
       "  'or',\n",
       "  'else',\n",
       "  'i',\n",
       "  'will',\n",
       "  'throw',\n",
       "  'each',\n",
       "  'one',\n",
       "  'of',\n",
       "  'you',\n",
       "  'into',\n",
       "  'the',\n",
       "  'water.',\n",
       "  '”',\n",
       "  'the',\n",
       "  'pirates',\n",
       "  'got',\n",
       "  'scared',\n",
       "  'and',\n",
       "  'immediately',\n",
       "  'released',\n",
       "  'the',\n",
       "  'princes',\n",
       "  '.'],\n",
       " ['she',\n",
       "  'quickly',\n",
       "  'dived',\n",
       "  'into',\n",
       "  'the',\n",
       "  'water',\n",
       "  'and',\n",
       "  'swam',\n",
       "  'to',\n",
       "  'the',\n",
       "  'safety',\n",
       "  'of',\n",
       "  'her',\n",
       "  'home',\n",
       "  '.'],\n",
       " ['soon',\n",
       "  'everyone',\n",
       "  'found',\n",
       "  'out',\n",
       "  'how',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'had',\n",
       "  'rescued',\n",
       "  'the',\n",
       "  'princess',\n",
       "  '.'],\n",
       " ['when',\n",
       "  'captain',\n",
       "  'hook',\n",
       "  'found',\n",
       "  'out',\n",
       "  'how',\n",
       "  'peter',\n",
       "  'had',\n",
       "  'tricked',\n",
       "  'his',\n",
       "  'men',\n",
       "  'he',\n",
       "  'was',\n",
       "  'furious',\n",
       "  '.'],\n",
       " ['and', 'swore', 'to', 'have', 'his', 'revenge', '.'],\n",
       " ['that',\n",
       "  'night',\n",
       "  'wendy',\n",
       "  'told',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  ',',\n",
       "  'that',\n",
       "  'she',\n",
       "  'and',\n",
       "  'her',\n",
       "  'brother',\n",
       "  'wanted',\n",
       "  'to',\n",
       "  'go',\n",
       "  'back',\n",
       "  'home',\n",
       "  'since',\n",
       "  'they',\n",
       "  'missed',\n",
       "  'their',\n",
       "  'parents',\n",
       "  '.'],\n",
       " ['she',\n",
       "  'said',\n",
       "  'if',\n",
       "  'the',\n",
       "  'lost',\n",
       "  'children',\n",
       "  'could',\n",
       "  'also',\n",
       "  'return',\n",
       "  'to',\n",
       "  'her',\n",
       "  'world',\n",
       "  'they',\n",
       "  'could',\n",
       "  'find',\n",
       "  'a',\n",
       "  'nice',\n",
       "  'home',\n",
       "  'for',\n",
       "  'them',\n",
       "  '.'],\n",
       " ['peter', 'pan', 'didn', '’', 't', 'want', 'to', 'leave', 'neverland', '.'],\n",
       " ['but',\n",
       "  'the',\n",
       "  'sake',\n",
       "  'of',\n",
       "  'the',\n",
       "  'lost',\n",
       "  'children',\n",
       "  'he',\n",
       "  'agreed',\n",
       "  ',',\n",
       "  'although',\n",
       "  'a',\n",
       "  'bit',\n",
       "  'sadly',\n",
       "  '.'],\n",
       " ['he', 'would', 'miss', 'his', 'friends', 'dearly', '.'],\n",
       " ['the',\n",
       "  'next',\n",
       "  'morning',\n",
       "  'all',\n",
       "  'the',\n",
       "  'lost',\n",
       "  'children',\n",
       "  'left',\n",
       "  'with',\n",
       "  'wendy',\n",
       "  ',',\n",
       "  'jhon',\n",
       "  ',',\n",
       "  'and',\n",
       "  'michael',\n",
       "  '.'],\n",
       " ['but',\n",
       "  'on',\n",
       "  'the',\n",
       "  'way',\n",
       "  ',',\n",
       "  'captain',\n",
       "  'hook',\n",
       "  'and',\n",
       "  'his',\n",
       "  'men',\n",
       "  'kidnapped',\n",
       "  'all',\n",
       "  'of',\n",
       "  'them',\n",
       "  '.'],\n",
       " ['he',\n",
       "  'tied',\n",
       "  'them',\n",
       "  'and',\n",
       "  'kept',\n",
       "  'them',\n",
       "  'on',\n",
       "  'once',\n",
       "  'of',\n",
       "  'his',\n",
       "  'ships',\n",
       "  '.'],\n",
       " ['as',\n",
       "  'soon',\n",
       "  'as',\n",
       "  'peter',\n",
       "  'found',\n",
       "  'out',\n",
       "  'about',\n",
       "  'it',\n",
       "  'he',\n",
       "  'rushed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'ship',\n",
       "  '.'],\n",
       " ['he',\n",
       "  'swung',\n",
       "  'himself',\n",
       "  'from',\n",
       "  'a',\n",
       "  'tress',\n",
       "  'branch',\n",
       "  'and',\n",
       "  'on',\n",
       "  'to',\n",
       "  'the',\n",
       "  'deck',\n",
       "  'of',\n",
       "  'the',\n",
       "  'ship',\n",
       "  'where',\n",
       "  'all',\n",
       "  'the',\n",
       "  'children',\n",
       "  'were',\n",
       "  'tied',\n",
       "  'up',\n",
       "  '.'],\n",
       " ['he',\n",
       "  'swung',\n",
       "  'his',\n",
       "  'sword',\n",
       "  'bravely',\n",
       "  'and',\n",
       "  'threw',\n",
       "  'over',\n",
       "  'the',\n",
       "  'pirates',\n",
       "  'who',\n",
       "  'tried',\n",
       "  'to',\n",
       "  'stop',\n",
       "  'him',\n",
       "  '.'],\n",
       " ['quickly',\n",
       "  'he',\n",
       "  'released',\n",
       "  'everyone',\n",
       "  'from',\n",
       "  'their',\n",
       "  'captor',\n",
       "  '’',\n",
       "  's',\n",
       "  'ties',\n",
       "  '.'],\n",
       " ['wendy',\n",
       "  ',',\n",
       "  'jhon',\n",
       "  ',',\n",
       "  'michael',\n",
       "  'and',\n",
       "  'tinker',\n",
       "  'bell',\n",
       "  'helped',\n",
       "  'all',\n",
       "  'the',\n",
       "  'children',\n",
       "  'into',\n",
       "  'the',\n",
       "  'water',\n",
       "  ',',\n",
       "  'where',\n",
       "  'their',\n",
       "  'friends',\n",
       "  'from',\n",
       "  'the',\n",
       "  'indian',\n",
       "  'camp',\n",
       "  'were',\n",
       "  'ready',\n",
       "  'with',\n",
       "  'smaller',\n",
       "  'boats',\n",
       "  'to',\n",
       "  'take',\n",
       "  'them',\n",
       "  'to',\n",
       "  'safety',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'now',\n",
       "  'went',\n",
       "  'looking',\n",
       "  'for',\n",
       "  'captain',\n",
       "  'hook',\n",
       "  '.'],\n",
       " ['“',\n",
       "  'let',\n",
       "  'us',\n",
       "  'finished',\n",
       "  'this',\n",
       "  'forever',\n",
       "  'mr.',\n",
       "  'hook',\n",
       "  '”',\n",
       "  ',',\n",
       "  'peter',\n",
       "  'challenged',\n",
       "  'captain',\n",
       "  'hook',\n",
       "  '.'],\n",
       " ['“', 'yes', '!'],\n",
       " ['peter',\n",
       "  'pan',\n",
       "  ',',\n",
       "  'you',\n",
       "  'have',\n",
       "  'caused',\n",
       "  'me',\n",
       "  'enough',\n",
       "  'trouble',\n",
       "  '.'],\n",
       " ['it',\n",
       "  'is',\n",
       "  'time',\n",
       "  'that',\n",
       "  'we',\n",
       "  'finished',\n",
       "  'this.',\n",
       "  '”',\n",
       "  'hook',\n",
       "  'replied',\n",
       "  '.'],\n",
       " ['with',\n",
       "  'his',\n",
       "  'sword',\n",
       "  'drawn',\n",
       "  ',',\n",
       "  'he',\n",
       "  'raced',\n",
       "  'towards',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  '.'],\n",
       " ['quick',\n",
       "  'on',\n",
       "  'his',\n",
       "  'feet',\n",
       "  ',',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'stepped',\n",
       "  'aside',\n",
       "  'and',\n",
       "  'pushed',\n",
       "  'hook',\n",
       "  'inside',\n",
       "  'the',\n",
       "  'sea',\n",
       "  'where',\n",
       "  'the',\n",
       "  'crocodile',\n",
       "  'was',\n",
       "  'waiting',\n",
       "  'to',\n",
       "  'eat',\n",
       "  'the',\n",
       "  'rest',\n",
       "  'of',\n",
       "  'hook',\n",
       "  '.'],\n",
       " ['everyone',\n",
       "  'rejoiced',\n",
       "  'as',\n",
       "  'captain',\n",
       "  'hook',\n",
       "  'was',\n",
       "  'out',\n",
       "  'of',\n",
       "  'their',\n",
       "  'lives',\n",
       "  'forever',\n",
       "  '.'],\n",
       " ['everybody', 'headed', 'back', 'to', 'london', '.'],\n",
       " ['mr.', 'and', 'mrs', '.'],\n",
       " ['darling',\n",
       "  'was',\n",
       "  'so',\n",
       "  'happy',\n",
       "  'to',\n",
       "  'see',\n",
       "  'their',\n",
       "  'children',\n",
       "  'and',\n",
       "  'they',\n",
       "  'agreed',\n",
       "  'to',\n",
       "  'adopt',\n",
       "  'the',\n",
       "  'lost',\n",
       "  'children',\n",
       "  '.'],\n",
       " ['they',\n",
       "  'even',\n",
       "  'asked',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'to',\n",
       "  'come',\n",
       "  'and',\n",
       "  'live',\n",
       "  'with',\n",
       "  'them',\n",
       "  '.'],\n",
       " ['but',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'said',\n",
       "  ',',\n",
       "  'he',\n",
       "  'never',\n",
       "  'wanted',\n",
       "  'to',\n",
       "  'grow',\n",
       "  'up',\n",
       "  ',',\n",
       "  'so',\n",
       "  'he',\n",
       "  'and',\n",
       "  'tinker',\n",
       "  'bell',\n",
       "  'will',\n",
       "  'go',\n",
       "  'back',\n",
       "  'to',\n",
       "  'neverland',\n",
       "  '.'],\n",
       " ['peter',\n",
       "  'pan',\n",
       "  'promised',\n",
       "  'everyone',\n",
       "  'that',\n",
       "  'he',\n",
       "  'will',\n",
       "  'visit',\n",
       "  'again',\n",
       "  'sometime',\n",
       "  '!'],\n",
       " ['and',\n",
       "  'he',\n",
       "  'flew',\n",
       "  'out',\n",
       "  'of',\n",
       "  'the',\n",
       "  'window',\n",
       "  'with',\n",
       "  'tinker',\n",
       "  'bell',\n",
       "  'by',\n",
       "  'his',\n",
       "  'side',\n",
       "  '.']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "import warnings \n",
    "warnings.filterwarnings(action = 'ignore') \n",
    "import gensim \n",
    "from gensim.models import Word2Vec\n",
    "  \n",
    "sample = open(\"data/peter.txt\", \"r\", encoding='UTF8')\n",
    "s = sample.read() \n",
    "  \n",
    "f = s.replace(\"\\n\", \" \")\n",
    "data = [] \n",
    "for i in sent_tokenize(f):\n",
    "    temp = [] \n",
    "    for j in word_tokenize(i):\n",
    "        temp.append(j.lower())\n",
    "    data.append(temp) \n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8789851f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcbd3aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between 'peter' wendy' - CBOW :  0.99999994\n"
     ]
    }
   ],
   "source": [
    "model1 = gensim.models.Word2Vec(data, min_count = 1,  \n",
    "                              vector_size = 100, window = 5, sg=0)\n",
    "print(\"Cosine similarity between 'peter' \" +\n",
    "                 \"wendy' - CBOW : \", \n",
    "      model1.wv.similarity('wendy', 'wendy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f6eac9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between 'peter' hook' - CBOW :  0.027709864\n"
     ]
    }
   ],
   "source": [
    "print(\"Cosine similarity between 'peter' \" +\n",
    "                 \"hook' - CBOW : \", \n",
    "      model1.wv.similarity('peter', 'hook')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08e2366f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Skip-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4fb8edd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between 'peter' wendy' - Skip Gram :  0.40088683\n"
     ]
    }
   ],
   "source": [
    "model2 = gensim.models.Word2Vec(data, min_count = 1, vector_size = 100, \n",
    "                                             window = 5, sg = 1)\n",
    "print(\"Cosine similarity between 'peter' \" +\n",
    "          \"wendy' - Skip Gram : \", \n",
    "    model2.wv.similarity('peter', 'wendy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8128bcb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between 'peter' hook' - Skip Gram :  0.5201673\n"
     ]
    }
   ],
   "source": [
    "print(\"Cosine similarity between 'peter' \" +\n",
    "            \"hook' - Skip Gram : \", \n",
    "      model2.wv.similarity('peter', 'hook')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f6e37fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20a1b279",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import FastText\n",
    "\n",
    "model = FastText('data/peter.txt', vector_size=4, window=3, min_count=1, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "216300d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4592452\n"
     ]
    }
   ],
   "source": [
    "sim_score = model.wv.similarity('peter', 'wendy')\n",
    "print(sim_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8afd9c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.043825716\n"
     ]
    }
   ],
   "source": [
    "sim_score = model.wv.similarity('peter', 'hook')\n",
    "print(sim_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4543f02c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KeyedVectors\n\u001b[1;32m----> 3\u001b[0m model_kr \u001b[38;5;241m=\u001b[39m \u001b[43mKeyedVectors\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_word2vec_format\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/wiki.ko.vec\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\torch_book\\lib\\site-packages\\gensim\\models\\keyedvectors.py:1719\u001b[0m, in \u001b[0;36mKeyedVectors.load_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header)\u001b[0m\n\u001b[0;32m   1672\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m   1673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_word2vec_format\u001b[39m(\n\u001b[0;32m   1674\u001b[0m         \u001b[38;5;28mcls\u001b[39m, fname, fvocab\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, binary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf8\u001b[39m\u001b[38;5;124m'\u001b[39m, unicode_errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1675\u001b[0m         limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, datatype\u001b[38;5;241m=\u001b[39mREAL, no_header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1676\u001b[0m     ):\n\u001b[0;32m   1677\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load KeyedVectors from a file produced by the original C word2vec-tool format.\u001b[39;00m\n\u001b[0;32m   1678\u001b[0m \n\u001b[0;32m   1679\u001b[0m \u001b[38;5;124;03m    Warnings\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1717\u001b[0m \n\u001b[0;32m   1718\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1719\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_word2vec_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1720\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbinary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43municode_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43municode_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1721\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatatype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatatype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mno_header\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mno_header\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1722\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\torch_book\\lib\\site-packages\\gensim\\models\\keyedvectors.py:2069\u001b[0m, in \u001b[0;36m_load_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header, binary_chunk_size)\u001b[0m\n\u001b[0;32m   2065\u001b[0m         _word2vec_read_binary(\n\u001b[0;32m   2066\u001b[0m             fin, kv, counts, vocab_size, vector_size, datatype, unicode_errors, binary_chunk_size, encoding\n\u001b[0;32m   2067\u001b[0m         )\n\u001b[0;32m   2068\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2069\u001b[0m         \u001b[43m_word2vec_read_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcounts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvector_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatatype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43municode_errors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2070\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kv\u001b[38;5;241m.\u001b[39mvectors\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(kv):\n\u001b[0;32m   2071\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[0;32m   2072\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mduplicate words detected, shrinking matrix size from \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2073\u001b[0m         kv\u001b[38;5;241m.\u001b[39mvectors\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mlen\u001b[39m(kv),\n\u001b[0;32m   2074\u001b[0m     )\n",
      "File \u001b[1;32m~\\.conda\\envs\\torch_book\\lib\\site-packages\\gensim\\models\\keyedvectors.py:1971\u001b[0m, in \u001b[0;36m_word2vec_read_text\u001b[1;34m(fin, kv, counts, vocab_size, vector_size, datatype, unicode_errors, encoding)\u001b[0m\n\u001b[0;32m   1969\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_word2vec_read_text\u001b[39m(fin, kv, counts, vocab_size, vector_size, datatype, unicode_errors, encoding):\n\u001b[0;32m   1970\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line_no \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(vocab_size):\n\u001b[1;32m-> 1971\u001b[0m         line \u001b[38;5;241m=\u001b[39m \u001b[43mfin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1972\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m line \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m   1973\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munexpected end of input; is count incorrect or file otherwise damaged?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "model_kr = KeyedVectors.load_word2vec_format('data/wiki.ko.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fb5c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_similar_to = '안녕'\n",
    "\n",
    "for similar_word in model_kr.similar_by_word(find_similar_to):\n",
    "    print(\"Word: {0}, Similarity: {1:.2f}\".format(\n",
    "        similar_word[0], similar_word[1]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346acbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = model_kr.most_similar(positive=['원숭이', '고릴라'], negative=['사람'])\n",
    "print(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376e7c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10.1.4 횟수/예측기반 임베딩\n",
    "#GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a8a9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "from sklearn.decomposition import PCA\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5752236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 100)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_file = \"C:/Users/2022-PC(T)-10/Desktop/SKAIFLY/sk_pytorch/data/glove.6B.100d.txt\"\n",
    "word2vec_glove_file = get_tmpfile(\"C:/Users/2022-PC(T)-10/Desktop/SKAIFLY/sk_pytorch/data/glove.6B.100d.word2vec.txt\")\n",
    "glove2word2vec(glove_file, word2vec_glove_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3db496ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('legislation', 0.8072139024734497),\n",
       " ('proposal', 0.7306862473487854),\n",
       " ('senate', 0.7142540812492371),\n",
       " ('bills', 0.7044401168823242),\n",
       " ('measure', 0.6958035230636597),\n",
       " ('passed', 0.690624475479126),\n",
       " ('amendment', 0.6846879720687866),\n",
       " ('provision', 0.684556782245636),\n",
       " ('plan', 0.6816462874412537),\n",
       " ('clinton', 0.6663140058517456)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = KeyedVectors.load_word2vec_format(word2vec_glove_file)\n",
    "model.most_similar('bill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d14331",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar('cherry') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c609124b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(negative='cherry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21c9f828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "another: 0.7313\n"
     ]
    }
   ],
   "source": [
    "result = model.most_similar(positive=['a', 'b'], negative=['o'])\n",
    "print(\"{}: {:.4f}\".format(*result[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "72881522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pyongyang'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def analogy(x1, x2, y1):\n",
    "    result = model.most_similar(positive=[y1, x2], negative=[x1])\n",
    "    return result[0][0]\n",
    "analogy('sad', 'korea', 'japan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9a8a76cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'longest'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy('tall', 'tallest', 'long')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "820bf3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cereal\n"
     ]
    }
   ],
   "source": [
    "print(model.doesnt_match(\"breakfast cereal dinner lunch\".split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b1d9c854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torch\n",
      "  Obtaining dependency information for torch from https://files.pythonhosted.org/packages/e4/ae/2ad8820045b6631965750435f28583e80905b8273d57cf026163b51323ee/torch-2.1.2-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading torch-2.1.2-cp311-cp311-win_amd64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (2023.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Downloading torch-2.1.2-cp311-cp311-win_amd64.whl (192.3 MB)\n",
      "   ---------------------------------------- 0.0/192.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/192.3 MB 3.5 MB/s eta 0:00:55\n",
      "   ---------------------------------------- 0.6/192.3 MB 7.4 MB/s eta 0:00:26\n",
      "   ---------------------------------------- 1.2/192.3 MB 9.4 MB/s eta 0:00:21\n",
      "   ---------------------------------------- 1.7/192.3 MB 9.9 MB/s eta 0:00:20\n",
      "   ---------------------------------------- 2.4/192.3 MB 10.9 MB/s eta 0:00:18\n",
      "    --------------------------------------- 2.8/192.3 MB 11.0 MB/s eta 0:00:18\n",
      "    --------------------------------------- 3.1/192.3 MB 10.4 MB/s eta 0:00:19\n",
      "    --------------------------------------- 3.4/192.3 MB 9.5 MB/s eta 0:00:20\n",
      "    --------------------------------------- 3.8/192.3 MB 9.4 MB/s eta 0:00:21\n",
      "    --------------------------------------- 4.4/192.3 MB 9.7 MB/s eta 0:00:20\n",
      "   - -------------------------------------- 5.1/192.3 MB 10.1 MB/s eta 0:00:19\n",
      "   - -------------------------------------- 5.8/192.3 MB 10.7 MB/s eta 0:00:18\n",
      "   - -------------------------------------- 6.4/192.3 MB 10.8 MB/s eta 0:00:18\n",
      "   - -------------------------------------- 7.2/192.3 MB 11.2 MB/s eta 0:00:17\n",
      "   - -------------------------------------- 8.0/192.3 MB 11.5 MB/s eta 0:00:16\n",
      "   - -------------------------------------- 8.6/192.3 MB 11.7 MB/s eta 0:00:16\n",
      "   - -------------------------------------- 9.4/192.3 MB 12.0 MB/s eta 0:00:16\n",
      "   -- ------------------------------------- 9.8/192.3 MB 12.0 MB/s eta 0:00:16\n",
      "   -- ------------------------------------- 10.2/192.3 MB 11.9 MB/s eta 0:00:16\n",
      "   -- ------------------------------------- 10.6/192.3 MB 11.9 MB/s eta 0:00:16\n",
      "   -- ------------------------------------- 11.1/192.3 MB 11.9 MB/s eta 0:00:16\n",
      "   -- ------------------------------------- 11.8/192.3 MB 11.9 MB/s eta 0:00:16\n",
      "   -- ------------------------------------- 12.5/192.3 MB 12.1 MB/s eta 0:00:15\n",
      "   -- ------------------------------------- 13.1/192.3 MB 12.4 MB/s eta 0:00:15\n",
      "   -- ------------------------------------- 14.0/192.3 MB 13.6 MB/s eta 0:00:14\n",
      "   --- ------------------------------------ 14.6/192.3 MB 13.6 MB/s eta 0:00:14\n",
      "   --- ------------------------------------ 15.3/192.3 MB 13.6 MB/s eta 0:00:13\n",
      "   --- ------------------------------------ 16.0/192.3 MB 13.6 MB/s eta 0:00:13\n",
      "   --- ------------------------------------ 16.6/192.3 MB 13.6 MB/s eta 0:00:13\n",
      "   --- ------------------------------------ 17.4/192.3 MB 13.6 MB/s eta 0:00:13\n",
      "   --- ------------------------------------ 18.2/192.3 MB 13.6 MB/s eta 0:00:13\n",
      "   --- ------------------------------------ 19.2/192.3 MB 13.9 MB/s eta 0:00:13\n",
      "   ---- ----------------------------------- 20.0/192.3 MB 14.6 MB/s eta 0:00:12\n",
      "   ---- ----------------------------------- 20.9/192.3 MB 15.6 MB/s eta 0:00:12\n",
      "   ---- ----------------------------------- 21.8/192.3 MB 16.4 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 22.8/192.3 MB 17.3 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 23.6/192.3 MB 17.2 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 24.4/192.3 MB 16.8 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 24.8/192.3 MB 16.8 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 25.6/192.3 MB 17.2 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 26.3/192.3 MB 17.2 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 27.2/192.3 MB 17.2 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 27.9/192.3 MB 17.3 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 28.8/192.3 MB 17.3 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 29.4/192.3 MB 17.2 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 30.2/192.3 MB 17.3 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 31.2/192.3 MB 16.8 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 31.6/192.3 MB 16.4 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 32.3/192.3 MB 16.0 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 33.1/192.3 MB 16.0 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 34.1/192.3 MB 15.6 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 34.8/192.3 MB 16.0 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 35.8/192.3 MB 16.8 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 36.4/192.3 MB 16.8 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 37.0/192.3 MB 16.4 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 37.8/192.3 MB 16.4 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 38.6/192.3 MB 16.4 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 39.7/192.3 MB 17.2 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 40.7/192.3 MB 17.7 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 41.5/192.3 MB 17.2 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 42.0/192.3 MB 17.7 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 42.6/192.3 MB 17.3 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 43.4/192.3 MB 17.3 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 44.1/192.3 MB 16.8 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 44.8/192.3 MB 16.0 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 45.5/192.3 MB 16.0 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 46.4/192.3 MB 16.0 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 47.1/192.3 MB 16.4 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 47.8/192.3 MB 16.4 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 48.7/192.3 MB 16.4 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 49.3/192.3 MB 16.4 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 49.9/192.3 MB 15.6 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 50.6/192.3 MB 15.2 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 51.1/192.3 MB 15.2 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 51.9/192.3 MB 14.9 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 52.7/192.3 MB 14.9 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 53.4/192.3 MB 15.2 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 54.5/192.3 MB 16.0 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 55.6/192.3 MB 16.8 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 56.7/192.3 MB 16.8 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 57.6/192.3 MB 17.2 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 58.7/192.3 MB 17.7 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 59.3/192.3 MB 18.2 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 60.3/192.3 MB 19.2 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 60.9/192.3 MB 18.7 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 61.5/192.3 MB 19.3 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 62.2/192.3 MB 18.7 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 62.9/192.3 MB 18.7 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 63.5/192.3 MB 18.2 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 64.3/192.3 MB 17.7 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 65.1/192.3 MB 17.7 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 66.1/192.3 MB 17.7 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 67.0/192.3 MB 17.2 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 68.0/192.3 MB 17.3 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 68.8/192.3 MB 17.2 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 69.8/192.3 MB 17.7 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 70.3/192.3 MB 16.8 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 70.5/192.3 MB 15.6 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 71.0/192.3 MB 15.2 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 71.6/192.3 MB 15.6 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 72.5/192.3 MB 16.0 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 73.4/192.3 MB 16.4 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 74.5/192.3 MB 16.8 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 75.4/192.3 MB 17.2 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 76.3/192.3 MB 17.3 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 77.0/192.3 MB 16.8 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 78.0/192.3 MB 16.8 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 78.9/192.3 MB 16.8 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 79.7/192.3 MB 16.8 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 80.3/192.3 MB 16.8 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 81.2/192.3 MB 18.7 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 81.4/192.3 MB 17.7 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 81.8/192.3 MB 17.7 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 82.4/192.3 MB 16.4 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 83.4/192.3 MB 16.8 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 84.0/192.3 MB 16.0 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 84.6/192.3 MB 15.6 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 85.3/192.3 MB 15.6 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 86.2/192.3 MB 15.2 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 87.0/192.3 MB 15.6 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 87.6/192.3 MB 14.9 MB/s eta 0:00:08\n",
      "   ------------------ --------------------- 88.4/192.3 MB 14.9 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 89.2/192.3 MB 14.9 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 89.9/192.3 MB 14.6 MB/s eta 0:00:08\n",
      "   ------------------ --------------------- 90.8/192.3 MB 14.9 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 92.0/192.3 MB 16.4 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 92.9/192.3 MB 17.2 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 94.2/192.3 MB 18.7 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 95.1/192.3 MB 18.7 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 95.9/192.3 MB 19.3 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 96.8/192.3 MB 18.7 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 97.5/192.3 MB 18.7 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 98.6/192.3 MB 19.8 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 99.3/192.3 MB 19.9 MB/s eta 0:00:05\n",
      "   -------------------- ------------------ 100.4/192.3 MB 20.5 MB/s eta 0:00:05\n",
      "   -------------------- ------------------ 101.2/192.3 MB 20.5 MB/s eta 0:00:05\n",
      "   -------------------- ------------------ 102.5/192.3 MB 20.5 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 103.6/192.3 MB 20.5 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 104.6/192.3 MB 20.5 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 105.6/192.3 MB 20.5 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 106.5/192.3 MB 20.5 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 107.2/192.3 MB 21.1 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 108.1/192.3 MB 21.1 MB/s eta 0:00:04\n",
      "   ---------------------- ---------------- 109.3/192.3 MB 21.8 MB/s eta 0:00:04\n",
      "   ---------------------- ---------------- 110.1/192.3 MB 21.8 MB/s eta 0:00:04\n",
      "   ---------------------- ---------------- 111.1/192.3 MB 21.8 MB/s eta 0:00:04\n",
      "   ---------------------- ---------------- 112.2/192.3 MB 21.8 MB/s eta 0:00:04\n",
      "   ---------------------- ---------------- 113.2/192.3 MB 21.1 MB/s eta 0:00:04\n",
      "   ----------------------- --------------- 114.4/192.3 MB 21.1 MB/s eta 0:00:04\n",
      "   ----------------------- --------------- 115.5/192.3 MB 21.8 MB/s eta 0:00:04\n",
      "   ----------------------- --------------- 116.4/192.3 MB 22.6 MB/s eta 0:00:04\n",
      "   ----------------------- --------------- 117.4/192.3 MB 21.8 MB/s eta 0:00:04\n",
      "   ----------------------- --------------- 118.3/192.3 MB 21.8 MB/s eta 0:00:04\n",
      "   ------------------------ -------------- 119.5/192.3 MB 21.8 MB/s eta 0:00:04\n",
      "   ------------------------ -------------- 120.7/192.3 MB 22.5 MB/s eta 0:00:04\n",
      "   ------------------------ -------------- 121.8/192.3 MB 22.6 MB/s eta 0:00:04\n",
      "   ------------------------ -------------- 122.9/192.3 MB 22.6 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 124.0/192.3 MB 22.6 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 125.2/192.3 MB 23.4 MB/s eta 0:00:03\n",
      "   ------------------------- ------------- 126.4/192.3 MB 23.4 MB/s eta 0:00:03\n",
      "   ------------------------- ------------- 127.3/192.3 MB 24.2 MB/s eta 0:00:03\n",
      "   -------------------------- ------------ 128.3/192.3 MB 25.2 MB/s eta 0:00:03\n",
      "   -------------------------- ------------ 129.2/192.3 MB 23.4 MB/s eta 0:00:03\n",
      "   -------------------------- ------------ 129.7/192.3 MB 23.4 MB/s eta 0:00:03\n",
      "   -------------------------- ------------ 130.2/192.3 MB 20.5 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 131.0/192.3 MB 20.5 MB/s eta 0:00:03\n",
      "   -------------------------- ------------ 131.5/192.3 MB 18.7 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 132.4/192.3 MB 19.3 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 133.4/192.3 MB 18.7 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 134.7/192.3 MB 18.7 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 135.9/192.3 MB 18.7 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 137.0/192.3 MB 18.2 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 138.1/192.3 MB 18.7 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 138.7/192.3 MB 18.7 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 140.2/192.3 MB 21.1 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 141.5/192.3 MB 22.6 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 142.4/192.3 MB 24.2 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 143.6/192.3 MB 25.2 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 144.6/192.3 MB 24.2 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 145.9/192.3 MB 24.2 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 147.2/192.3 MB 25.1 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 148.2/192.3 MB 25.1 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 149.8/192.3 MB 26.2 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 151.1/192.3 MB 26.2 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 151.9/192.3 MB 25.2 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 152.9/192.3 MB 25.2 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 154.0/192.3 MB 25.2 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 155.0/192.3 MB 25.2 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 155.9/192.3 MB 24.2 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 157.3/192.3 MB 24.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 158.5/192.3 MB 25.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 159.8/192.3 MB 24.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 161.4/192.3 MB 25.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 162.9/192.3 MB 26.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 163.8/192.3 MB 26.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 164.7/192.3 MB 26.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 165.7/192.3 MB 26.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 166.9/192.3 MB 26.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 168.1/192.3 MB 26.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 169.1/192.3 MB 25.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 170.5/192.3 MB 25.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 171.8/192.3 MB 25.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 172.9/192.3 MB 24.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 173.5/192.3 MB 22.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 174.1/192.3 MB 22.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 174.8/192.3 MB 21.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 175.9/192.3 MB 21.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 177.1/192.3 MB 21.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 178.3/192.3 MB 21.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 179.7/192.3 MB 22.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 181.0/192.3 MB 22.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 182.2/192.3 MB 22.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 183.2/192.3 MB 22.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 184.5/192.3 MB 26.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 185.3/192.3 MB 25.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 186.5/192.3 MB 25.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  187.7/192.3 MB 25.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  189.0/192.3 MB 25.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  190.1/192.3 MB 24.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  191.2/192.3 MB 24.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  192.2/192.3 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  192.3/192.3 MB 24.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  192.3/192.3 MB 24.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  192.3/192.3 MB 24.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  192.3/192.3 MB 24.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  192.3/192.3 MB 24.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  192.3/192.3 MB 24.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  192.3/192.3 MB 24.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  192.3/192.3 MB 24.2 MB/s eta 0:00:01\n",
      "   --------------------------------------- 192.3/192.3 MB 10.7 MB/s eta 0:00:00\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-2.1.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts convert-caffe2-to-onnx.exe, convert-onnx-to-caffe2.exe and torchrun.exe are installed in 'C:\\Users\\2022-PC(T)-10\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "#10.2 Transformer attention\n",
    "#10.2.1 Seq2seq\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6ae5b052",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m unicode_literals, print_function, division\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4841b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "MAX_LENGTH = 20\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self):\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  \n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ebe3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeString(df, lang):\n",
    "    sentence = df[lang].str.lower()\n",
    "    sentence = sentence.str.replace('[^A-Za-z\\s]+', '')\n",
    "    sentence = sentence.str.normalize('NFD')\n",
    "    sentence = sentence.str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "    return sentence\n",
    "\n",
    "def read_sentence(df, lang1, lang2):\n",
    "    sentence1 = normalizeString(df, lang1)\n",
    "    sentence2 = normalizeString(df, lang2)\n",
    "    return sentence1, sentence2\n",
    "\n",
    "def read_file(loc, lang1, lang2):\n",
    "    df = pd.read_csv(loc, delimiter='\\t', header=None, names=[lang1, lang2])\n",
    "    return df\n",
    "\n",
    "def process_data(lang1,lang2):\n",
    "    df = read_file('data/%s-%s.txt' % (lang1, lang2), lang1, lang2)\n",
    "    sentence1, sentence2 = read_sentence(df, lang1, lang2)\n",
    "\n",
    "    input_lang = Lang()\n",
    "    output_lang = Lang()\n",
    "    pairs = []\n",
    "    for i in range(len(df)):\n",
    "        if len(sentence1[i].split(' ')) < MAX_LENGTH and len(sentence2[i].split(' ')) < MAX_LENGTH:\n",
    "            full = [sentence1[i], sentence2[i]]\n",
    "            input_lang.addSentence(sentence1[i])\n",
    "            output_lang.addSentence(sentence2[i])\n",
    "            pairs.append(full)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c3e7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "def tensorsFromPair(input_lang, output_lang, pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cda608",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, embbed_dim, num_layers):\n",
    "        super(Encoder, self).__init__()       \n",
    "        self.input_dim = input_dim\n",
    "        self.embbed_dim = embbed_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(input_dim, self.embbed_dim)\n",
    "        self.gru = nn.GRU(self.embbed_dim, self.hidden_dim, num_layers=self.num_layers)\n",
    "              \n",
    "    def forward(self, src):      \n",
    "        embedded = self.embedding(src).view(1,1,-1)\n",
    "        outputs, hidden = self.gru(embedded)\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8c263c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, hidden_dim, embbed_dim, num_layers):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.embbed_dim = embbed_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(output_dim, self.embbed_dim)\n",
    "        self.gru = nn.GRU(self.embbed_dim, self.hidden_dim, num_layers=self.num_layers)\n",
    "        self.out = nn.Linear(self.hidden_dim, output_dim)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "      \n",
    "    def forward(self, input, hidden):\n",
    "        input = input.view(1, -1)\n",
    "        embedded = F.relu(self.embedding(input))\n",
    "        output, hidden = self.gru(embedded, hidden)       \n",
    "        prediction = self.softmax(self.out(output[0]))      \n",
    "        return prediction, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2e32442e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device, MAX_LENGTH=MAX_LENGTH):\n",
    "        super().__init__()\n",
    "      \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "     \n",
    "    def forward(self, input_lang, output_lang, teacher_forcing_ratio=0.5):\n",
    "\n",
    "        input_length = input_lang.size(0)\n",
    "        batch_size = output_lang.shape[1] \n",
    "        target_length = output_lang.shape[0]\n",
    "        vocab_size = self.decoder.output_dim      \n",
    "        outputs = torch.zeros(target_length, batch_size, vocab_size).to(self.device)\n",
    "\n",
    "        for i in range(input_length):\n",
    "            encoder_output, encoder_hidden = self.encoder(input_lang[i])\n",
    "\n",
    "        decoder_hidden = encoder_hidden.to(device)  \n",
    "        decoder_input = torch.tensor([SOS_token], device=device)  \n",
    "\n",
    "        for t in range(target_length):   \n",
    "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
    "            outputs[t] = decoder_output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            input = (output_lang[t] if teacher_force else topi)\n",
    "            if(teacher_force == False and input.item() == EOS_token):\n",
    "                break\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "93d4ebc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "def Model(model, input_tensor, target_tensor, model_optimizer, criterion):\n",
    "    model_optimizer.zero_grad()\n",
    "    input_length = input_tensor.size(0)\n",
    "    loss = 0\n",
    "    epoch_loss = 0\n",
    "    output = model(input_tensor, target_tensor)\n",
    "    num_iter = output.size(0)\n",
    "\n",
    "    for ot in range(num_iter):\n",
    "        loss += criterion(output[ot], target_tensor[ot])\n",
    "\n",
    "    loss.backward()\n",
    "    model_optimizer.step()\n",
    "    epoch_loss = loss.item() / num_iter\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9768b4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(model, input_lang, output_lang, pairs, num_iteration=20000):\n",
    "    model.train()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "    criterion = nn.NLLLoss()\n",
    "    total_loss_iterations = 0\n",
    "\n",
    "    training_pairs = [tensorsFromPair(input_lang, output_lang, random.choice(pairs))\n",
    "                      for i in range(num_iteration)]ㅇ\n",
    "  \n",
    "    for iter in range(1, num_iteration+1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "        loss = Model(model, input_tensor, target_tensor, optimizer, criterion)\n",
    "        total_loss_iterations += loss\n",
    "\n",
    "        if iter % 5000 == 0:\n",
    "            average_loss= total_loss_iterations / 5000\n",
    "            total_loss_iterations = 0\n",
    "            print('%d %.4f' % (iter, average_loss))\n",
    "          \n",
    "    torch.save(model.state_dict(), 'data/mytraining.pt')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9bd2079f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, input_lang, output_lang, sentences, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentences[0])\n",
    "        output_tensor = tensorFromSentence(output_lang, sentences[1])  \n",
    "        decoded_words = []  \n",
    "        output = model(input_tensor, output_tensor)\n",
    "  \n",
    "        for ot in range(output.size(0)):\n",
    "            topv, topi = output[ot].topk(1)\n",
    "\n",
    "            if topi[0].item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi[0].item()])\n",
    "    return decoded_words\n",
    "\n",
    "def evaluateRandomly(model, input_lang, output_lang, pairs, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('input {}'.format(pair[0]))\n",
    "        print('output {}'.format(pair[1]))\n",
    "        output_words = evaluate(model, input_lang, output_lang, pair)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('predicted {}'.format(output_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b6814115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random sentence ['she wrapped the present in paper.', 'elle a emballe le cadeau dans du papier.']\n",
      "Input : 23191 Output : 39387\n",
      "Encoder(\n",
      "  (embedding): Embedding(23191, 256)\n",
      "  (gru): GRU(256, 512)\n",
      ")\n",
      "Decoder(\n",
      "  (embedding): Embedding(39387, 256)\n",
      "  (gru): GRU(256, 512)\n",
      "  (out): Linear(in_features=512, out_features=39387, bias=True)\n",
      "  (softmax): LogSoftmax(dim=1)\n",
      ")\n",
      "5000 5.0397\n",
      "10000 4.7935\n",
      "15000 4.7390\n",
      "20000 4.6502\n",
      "25000 4.6782\n",
      "30000 4.6451\n",
      "35000 4.5951\n",
      "40000 4.5947\n",
      "45000 4.5694\n",
      "50000 4.5920\n",
      "55000 4.5776\n",
      "60000 4.6143\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(encoder)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(decoder)\n\u001b[1;32m---> 25\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrainModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_lang\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_lang\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpairs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_iteration\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[51], line 14\u001b[0m, in \u001b[0;36mtrainModel\u001b[1;34m(model, input_lang, output_lang, pairs, num_iteration)\u001b[0m\n\u001b[0;32m     12\u001b[0m input_tensor \u001b[38;5;241m=\u001b[39m training_pair[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     13\u001b[0m target_tensor \u001b[38;5;241m=\u001b[39m training_pair[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m---> 14\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m total_loss_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28miter\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m5000\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[1;32mIn[50], line 16\u001b[0m, in \u001b[0;36mModel\u001b[1;34m(model, input_tensor, target_tensor, model_optimizer, criterion)\u001b[0m\n\u001b[0;32m     14\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     15\u001b[0m model_optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 16\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m num_iter\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m epoch_loss\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lang1 = 'eng'\n",
    "lang2 = 'fra'\n",
    "input_lang, output_lang, pairs = process_data(lang1, lang2)\n",
    "\n",
    "randomize = random.choice(pairs)\n",
    "print('random sentence {}'.format(randomize))\n",
    "\n",
    "input_size = input_lang.n_words\n",
    "output_size = output_lang.n_words\n",
    "print('Input : {} Output : {}'.format(input_size, output_size))\n",
    "\n",
    "embed_size = 256\n",
    "hidden_size = 512\n",
    "num_layers = 1\n",
    "num_iteration = 75000\n",
    "\n",
    "encoder = Encoder(input_size, hidden_size, embed_size, num_layers)\n",
    "decoder = Decoder(output_size, hidden_size, embed_size, num_layers)\n",
    "\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)\n",
    " \n",
    "print(encoder)\n",
    "print(decoder)\n",
    "\n",
    "model = trainModel(model, input_lang, output_lang, pairs, num_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2807a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluateRandomly(model, input_lang, output_lang, pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6032888a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb7ef62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  \n",
    "    plot_loss_total = 0  \n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(input_lang, output_lang, random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "        loss = Model(model, input_tensor, target_tensor, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % 5000 == 0:\n",
    "            print_loss_avg = print_loss_total / 5000\n",
    "            print_loss_total = 0\n",
    "            print('%d,  %.4f' % (iter, print_loss_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df879d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 256\n",
    "hidden_size = 512\n",
    "num_layers = 1\n",
    "input_size = input_lang.n_words\n",
    "output_size = output_lang.n_words\n",
    "\n",
    "encoder1 = Encoder(input_size, hidden_size, embed_size, num_layers)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_size, dropout_p=0.1).to(device)\n",
    "\n",
    "print(encoder1)\n",
    "print(attn_decoder1)\n",
    "\n",
    "attn_model = trainIters(encoder1, attn_decoder1, 75000, print_every=5000, plot_every=100, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201fd8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10.2.1 Bert\n",
    "#!pip install transformers\n",
    "#!pip install pytorch-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e37965-ce8f-4650-be38-5fa6302803df",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytorch_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b91e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from pytorch_transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa39b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/training.txt', sep='\\t')\n",
    "valid_df = pd.read_csv('data/validing.txt', sep='\\t')\n",
    "test_df = pd.read_csv('data/testing.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e620c35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.sample(frac=0.1, random_state=500)\n",
    "valid_df = valid_df.sample(frac=0.1, random_state=500)\n",
    "test_df = test_df.sample(frac=0.1, random_state=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8506022e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Datasets(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.df.iloc[idx, 1]\n",
    "        label = self.df.iloc[idx, 2]\n",
    "        return text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97277c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Datasets(train_df)\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=0)\n",
    "\n",
    "valid_dataset = Datasets(valid_df)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=2, shuffle=True, num_workers=0)\n",
    "\n",
    "test_dataset = Datasets(test_df)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106307e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0f5fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(save_path, model, valid_loss):\n",
    "    if save_path == None:\n",
    "        return    \n",
    "    state_dict = {'model_state_dict': model.state_dict(),\n",
    "                  'valid_loss': valid_loss}\n",
    "    \n",
    "    torch.save(state_dict, save_path)\n",
    "    print(f'Model saved to ==> {save_path}')\n",
    "\n",
    "def load_checkpoint(load_path, model):    \n",
    "    if load_path==None:\n",
    "        return    \n",
    "    state_dict = torch.load(load_path, map_location=device)\n",
    "    print(f'Model loaded from <== {load_path}')\n",
    "    \n",
    "    model.load_state_dict(state_dict['model_state_dict'])\n",
    "    return state_dict['valid_loss']\n",
    "\n",
    "def save_metrics(save_path, train_loss_list, valid_loss_list, global_steps_list):\n",
    "    if save_path == None:\n",
    "        return    \n",
    "    state_dict = {'train_loss_list': train_loss_list,\n",
    "                  'valid_loss_list': valid_loss_list,\n",
    "                  'global_steps_list': global_steps_list}    \n",
    "    torch.save(state_dict, save_path)\n",
    "    print(f'Model saved to ==> {save_path}')\n",
    "\n",
    "def load_metrics(load_path):\n",
    "    if load_path==None:\n",
    "        return    \n",
    "    state_dict = torch.load(load_path, map_location=device)\n",
    "    print(f'Model loaded from <== {load_path}')    \n",
    "    return state_dict['train_loss_list'], state_dict['valid_loss_list'], state_dict['global_steps_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0871e661",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,\n",
    "          optimizer,\n",
    "          criterion = nn.BCELoss(),\n",
    "          num_epochs = 5,\n",
    "          eval_every = len(train_loader) // 2,\n",
    "          best_valid_loss = float(\"Inf\")):\n",
    "    \n",
    "    total_correct = 0.0\n",
    "    total_len = 0.0\n",
    "    running_loss = 0.0\n",
    "    valid_running_loss = 0.0\n",
    "    global_step = 0\n",
    "    train_loss_list = []\n",
    "    valid_loss_list = []\n",
    "    global_steps_list = []\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for text, label in train_loader:\n",
    "            optimizer.zero_grad()        \n",
    "            encoded_list = [tokenizer.encode(t, add_special_tokens=True) for t in text]\n",
    "            padded_list =  [e + [0] * (512-len(e)) for e in encoded_list]\n",
    "        \n",
    "            sample = torch.tensor(padded_list)\n",
    "            sample, label = sample.to(device), label.to(device)\n",
    "            labels = torch.tensor(label)\n",
    "            outputs = model(sample, labels=labels)\n",
    "            loss, logits = outputs\n",
    "\n",
    "            pred = torch.argmax(F.softmax(logits), dim=1)\n",
    "            correct = pred.eq(labels)\n",
    "            total_correct += correct.sum().item()\n",
    "            total_len += len(labels)\n",
    "            running_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()        \n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_every == 0:\n",
    "                model.eval()\n",
    "                with torch.no_grad():                    \n",
    "                    for text, label in valid_loader:\n",
    "                        encoded_list = [tokenizer.encode(t, add_special_tokens=True) for t in text]\n",
    "                        padded_list =  [e + [0] * (512-len(e)) for e in encoded_list]        \n",
    "                        sample = torch.tensor(padded_list)\n",
    "                        sample, label = sample.to(device), label.to(device)\n",
    "                        labels = torch.tensor(label)\n",
    "                        outputs = model(sample, labels=labels)\n",
    "                        loss, logits = outputs                        \n",
    "                        valid_running_loss += loss.item()\n",
    "\n",
    "                average_train_loss = running_loss / eval_every\n",
    "                average_valid_loss = valid_running_loss / len(valid_loader)\n",
    "                train_loss_list.append(average_train_loss)\n",
    "                valid_loss_list.append(average_valid_loss)\n",
    "                global_steps_list.append(global_step)\n",
    "\n",
    "                running_loss = 0.0                \n",
    "                valid_running_loss = 0.0\n",
    "                model.train()\n",
    "\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}'\n",
    "                      .format(epoch+1, num_epochs, global_step, num_epochs*len(train_loader),\n",
    "                              average_train_loss, average_valid_loss))\n",
    "                \n",
    "                if best_valid_loss > average_valid_loss:\n",
    "                    best_valid_loss = average_valid_loss\n",
    "                    save_checkpoint('data/model.pt', model, best_valid_loss)\n",
    "                    save_metrics('data/metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
    "    \n",
    "    save_metrics('data/metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
    "    print('훈련 종료!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f69dac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=2e-5)\n",
    "train(model=model, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abbb6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_list, valid_loss_list, global_steps_list = load_metrics('data/metrics.pt')\n",
    "plt.plot(global_steps_list, train_loss_list, label='Train')\n",
    "plt.plot(global_steps_list, valid_loss_list, label='Valid')\n",
    "plt.xlabel('Global Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb68692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for text, label in test_loader:\n",
    "            encoded_list = [tokenizer.encode(t, add_special_tokens=True) for t in text]\n",
    "            padded_list =  [e + [0] * (512-len(e)) for e in encoded_list]\n",
    "        \n",
    "            sample = torch.tensor(padded_list)\n",
    "            sample, label = sample.to(device), label.to(device)\n",
    "            labels = torch.tensor(label)\n",
    "            output = model(sample, labels=labels)\n",
    "            \n",
    "            _, output = output\n",
    "            y_pred.extend(torch.argmax(output, 1).tolist())\n",
    "            y_true.extend(labels.tolist())\n",
    "                    \n",
    "    print('Classification 결과:')\n",
    "    print(classification_report(y_true, y_pred, labels=[1,0], digits=4))\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[1,0])\n",
    "    ax= plt.subplot()\n",
    "    sns.heatmap(cm, annot=True, ax = ax, cmap='Blues', fmt=\"d\")\n",
    "    \n",
    "    ax.set_title('Confusion Matrix')\n",
    "    ax.set_xlabel('Predicted Labels')\n",
    "    ax.set_ylabel('True Labels')\n",
    "    ax.xaxis.set_ticklabels(['0', '1'])\n",
    "    ax.yaxis.set_ticklabels(['0', '1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dfe435",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = model.to(device)\n",
    "load_checkpoint('data/model.pt', best_model)\n",
    "evaluate(best_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64b382c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10.3 한국어 임베딩\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14558a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe6d8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"나는 파이토치를 이용한 딥러닝을 학습중이다.\"\n",
    "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "tokenized_text = tokenizer.tokenize(marked_text)\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3740f31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"과수원에 사과가 많았다.\" \\\n",
    "       \"친구가 나에게 사과했다.\"\\\n",
    "       \"백설공주는 독이 든 사과를 먹었다.\"\n",
    "\n",
    "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "tokenized_text = tokenizer.tokenize(marked_text)\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "for tup in zip(tokenized_text, indexed_tokens):\n",
    "    print('{:<12} {:>6,}'.format(tup[0], tup[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da9f047",
   "metadata": {},
   "outputs": [],
   "source": [
    "segments_ids = [1] * len(tokenized_text)\n",
    "print (segments_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9a81c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2637806e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertModel.from_pretrained('bert-base-multilingual-cased',\n",
    "                                  output_hidden_states = True,)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba79d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(tokens_tensor, segments_tensors)\n",
    "    hidden_states = outputs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61815e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"계층 수:\", len(hidden_states), \"  (initial embeddings + 12 BERT layers)\")\n",
    "layer_i = 0\n",
    "\n",
    "print (\"배치 수:\", len(hidden_states[layer_i]))\n",
    "batch_i = 0\n",
    "\n",
    "print (\"토큰 수:\", len(hidden_states[layer_i][batch_i]))\n",
    "token_i = 0\n",
    "\n",
    "print (\"은닉층 유닛 수:\", len(hidden_states[layer_i][batch_i][token_i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c79e83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('은닉 상태의 유형: ', type(hidden_states))\n",
    "print('각 계층에서의 텐서 형태: ', hidden_states[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9633fe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_embeddings = torch.stack(hidden_states, dim=0)\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d777453",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6a4d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_embeddings = token_embeddings.permute(1,0,2)\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2f7874",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_vecs_cat = []\n",
    "for token in token_embeddings:\n",
    "    cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
    "    token_vecs_cat.append(cat_vec)\n",
    "print ('형태는: %d x %d' % (len(token_vecs_cat), len(token_vecs_cat[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7621bc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_vecs_sum = []\n",
    "for token in token_embeddings:\n",
    "    sum_vec = torch.sum(token[-4:], dim=0)\n",
    "    token_vecs_sum.append(sum_vec)\n",
    "print ('형태는: %d x %d' % (len(token_vecs_sum), len(token_vecs_sum[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a14ae7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_vecs = hidden_states[-2][0]\n",
    "sentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "print (\"최종 임베딩 벡터의 형태:\", sentence_embedding.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b581d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, token_str in enumerate(tokenized_text):\n",
    "    print (i, token_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb56c9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"사과가 많았다\", str(token_vecs_sum[6][:5]))\n",
    "print(\"나에게 사과했다\", str(token_vecs_sum[10][:5]))\n",
    "print(\"사과를 먹었다\", str(token_vecs_sum[19][:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc2e65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "diff_apple = 1 - cosine(token_vecs_sum[5], token_vecs_sum[27])\n",
    "same_apple = 1 - cosine(token_vecs_sum[5], token_vecs_sum[16])\n",
    "print('*유사한* 의미에 대한 벡터 유사성:  %.2f' % same_apple)\n",
    "print('*다른* 의미에 대한 벡터 유사성:  %.2f' % diff_apple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1c53aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda37a6d-fb36-4946-b381-bd16ab568c37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cc6308-72e8-4648-bc10-9ee6676b149f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0741d19e-a3fc-43dd-b6ba-9e5816883aef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177c45ee-5d35-4b9a-8f15-54c3661a282e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4d79fa-99d1-4afa-9d59-96eda633eb49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638e6fba-983b-4742-9fad-2d1e93d165ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7c10b5-247d-444d-ae50-16748d78036d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7e52e0-fc8d-4aa6-9dd4-4a080e6b84d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee3fcfa-bbc7-495e-8769-9101ae55bb04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c4baa7-bfa7-4cbe-a1f7-88c5e964458d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f3d921-3ade-4883-8b10-271498f25dde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901bcdf0-b340-4c48-8b47-50208b50c80d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caba3289-b10f-4b3e-af3b-473821f0cb42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d888e47-8a0c-4e0a-bb20-4466ff4509f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b02640-1277-409f-801d-49cd93287254",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5bc3e4-36d5-4def-9e4c-5ecd8fce77b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ebbd51-c348-4071-bba8-5f0b94c00084",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfe7f6c-cd73-4bac-ae91-dc6ce556666a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80db2d6e-d361-448c-913b-50902d9c5e94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096823ad-69c2-45e5-88e0-7aa2933cfa1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d2c360-fc33-4a20-bec9-05bb883f19a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b66672-b79b-4fc9-8d54-c4c22367da89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd15e25-1f62-44fb-988b-1f280e59c0af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029ea031-6b57-4ff9-8758-461e87906b05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc9e8d6-d157-4819-aa87-52a4fa9dfe20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde493b1-564c-4254-b592-2c481cb0d81a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f1f5ef-4897-4136-a945-abdf68c1bc87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3308b113-8dcd-48eb-8b1b-a4ad7bb67c5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5ec687-c0a1-4463-b4dd-df0fec044e08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c323d199-1486-418c-b625-8c6ab0c2d160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830353e2-1933-4b92-a5fc-befc8b1d6e46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3a486e-6294-4b8f-83c4-3106ff4b3d7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd17265d-78b4-41a6-9843-b44eeaadba70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec696fc7-8dbe-4494-9c14-4fe4eae2a252",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdabd99-c506-4c2f-8ffd-9a2d42816d00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a442da-c76d-42b3-a7bf-b9764bc0bf96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfad645-3955-44cb-bf26-a9fff956c8ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d5b8e2-0170-436d-a1f2-c325e2b69e62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cc2a38-0420-45af-b65e-052299a160d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d80d19-4361-4aca-aa74-d8cf02f1ff86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae34ee4f-8b38-4baa-9fd7-d8c45729afc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b08947-6310-49ba-bec4-9483e2380561",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f684f9-4d19-4e59-96ca-98410b84c911",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fd9455-8211-44ca-97ef-c490e0a73648",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c623451-111d-437e-865c-e036fe6b7e14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a1106c-15b8-46dd-aeee-23cd14f67350",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614d2799-f135-4c82-82f0-6e25eabc9504",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de02d62e-d39e-4324-9ab8-5cd1b178bc90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca55909-5a5b-48d5-99b1-1232c3d5881a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef5c823-5ec5-4e66-a573-ef1e167bb3ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e44f85-335a-4428-92df-cab79f467e8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76812f78-927b-4d05-870f-a9f5674c4405",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f07a7b0-43d6-4e4f-ae41-d07a03d4c050",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ed96b4-6904-4d97-8f80-be9f2164ef49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653b8299-9261-44cb-acb1-00d777094435",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f57ada-80ec-4e1c-8466-1815e2a3411f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06724351-bb9e-4f75-ab20-53283ac17ea4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4eb68f-f157-40f7-8e86-0a65106f92e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67476273-758e-49d4-8349-3fc7ae658e6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c996a8-0579-4caf-b362-19437bac1bdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
