{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/barabonda/SK-AI-FLY/blob/main/4%EC%A3%BC%EC%B0%A8/atari_breakout_cuda_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1DR5X85xrva",
        "outputId": "4d223e33-c49b-4284-8cb0-0249e16c826c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gym[accept-rom-license,atari]==0.26.2\n",
            "  Downloading gym-0.26.2.tar.gz (721 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m721.7/721.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym[accept-rom-license,atari]==0.26.2) (1.23.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym[accept-rom-license,atari]==0.26.2) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym[accept-rom-license,atari]==0.26.2) (0.0.8)\n",
            "Collecting autorom[accept-rom-license]~=0.4.2 (from gym[accept-rom-license,atari]==0.26.2)\n",
            "  Downloading AutoROM-0.4.2-py3-none-any.whl (16 kB)\n",
            "Collecting ale-py~=0.8.0 (from gym[accept-rom-license,atari]==0.26.2)\n",
            "  Downloading ale_py-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from ale-py~=0.8.0->gym[accept-rom-license,atari]==0.26.2) (6.1.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from ale-py~=0.8.0->gym[accept-rom-license,atari]==0.26.2) (4.5.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]==0.26.2) (8.1.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]==0.26.2) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]==0.26.2) (4.66.1)\n",
            "Collecting AutoROM.accept-rom-license (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]==0.26.2)\n",
            "  Downloading AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]==0.26.2) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]==0.26.2) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]==0.26.2) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]==0.26.2) (2023.11.17)\n",
            "Building wheels for collected packages: gym, AutoROM.accept-rom-license\n",
            "  Building wheel for gym (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.26.2-py3-none-any.whl size=827619 sha256=598be49069cf6075c13ee66db569ea530f59a94bf686b1086ec5560cfc9aff51\n",
            "  Stored in directory: /root/.cache/pip/wheels/b9/22/6d/3e7b32d98451b4cd9d12417052affbeeeea012955d437da1da\n",
            "  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.6.1-py3-none-any.whl size=446660 sha256=f2eb4e8bba4db95d389b9444b4776b771a8b6da186a2c7ebb4fe8b534732cd24\n",
            "  Stored in directory: /root/.cache/pip/wheels/6b/1b/ef/a43ff1a2f1736d5711faa1ba4c1f61be1131b8899e6a057811\n",
            "Successfully built gym AutoROM.accept-rom-license\n",
            "Installing collected packages: gym, ale-py, AutoROM.accept-rom-license, autorom\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.25.2\n",
            "    Uninstalling gym-0.25.2:\n",
            "      Successfully uninstalled gym-0.25.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.0.6 requires gym<=0.25.2, but you have gym 0.26.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed AutoROM.accept-rom-license-0.6.1 ale-py-0.8.1 autorom-0.4.2 gym-0.26.2\n"
          ]
        }
      ],
      "source": [
        "!pip install gym[atari,accept-rom-license]==0.26.2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "env = gym.make(\"BreakoutNoFrameskip-v4\", render_mode='rgb_array')"
      ],
      "metadata": {
        "id": "pV0fajGOxxZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obs, info = env.reset()"
      ],
      "metadata": {
        "id": "7xyi5_cuycwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vCHE0a2ys7V",
        "outputId": "5d7af94c-4dc9-453d-b02c-797e601e0d7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0]]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "obs.shape # HWC -> CHW R의 대한 한판 G에 대한 한판 B에 대한 한 GPU cashing에서 이득이 있다"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_stED335yuTJ",
        "outputId": "98f790e8-2948-4ee1-b064-41eb6f8d1e07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(210, 160, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "info"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7DIo2_4yzuP",
        "outputId": "af672cc8-6f13-41f4-95a9-520513b60923"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'lives': 5, 'episode_frame_number': 0, 'frame_number': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(obs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "bPA8ldgKy5vx",
        "outputId": "ccf24d22-ee96-4ed9-cba8-30770ed02ea1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7d0ad9c3c1f0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "obs_next, reward, done, _, info = env.step(1)"
      ],
      "metadata": {
        "id": "djbqyEELzI5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(obs_next)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "984P5b9IzqzM",
        "outputId": "8cb8e2b2-deb4-4138-aee3-ec220f6da103"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7d0ad7b59ba0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as T\n",
        "\n",
        "# Configuration paramaters for the whole setup\n",
        "seed = 42\n",
        "gamma = 0.99  # Discount factor for past rewards\n",
        "epsilon = 1.0  # Epsilon greedy parameter\n",
        "epsilon_min = 0.1  # Minimum epsilon greedy parameter\n",
        "epsilon_max = 1.0  # Maximum epsilon greedy parameter\n",
        "epsilon_interval = (\n",
        "    epsilon_max - epsilon_min\n",
        ")  # Rate at which to reduce chance of random action being taken\n",
        "batch_size = 64  # Size of batch taken from replay buffer\n",
        "max_steps_per_episode = 1000"
      ],
      "metadata": {
        "id": "WZ5JPdNSzupR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_actions = env.action_space.n\n",
        "\n",
        "class QModel(nn.Module):\n",
        "    def __init__(self, num_actions):\n",
        "        super(QModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=8, stride=4)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\n",
        "        self.dropout = nn.Dropout(p=0.3)\n",
        "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(3136, 512)\n",
        "        self.fc2 = nn.Linear(512, num_actions)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = nn.functional.relu(self.conv1(x))\n",
        "        x = nn.functional.relu(self.conv2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = nn.functional.relu(self.conv3(x))\n",
        "        x = self.flatten(x)\n",
        "        x = nn.functional.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        action = self.fc2(x)\n",
        "        return action"
      ],
      "metadata": {
        "id": "dc4_u5zq0gWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The first model makes the predictions for Q-values which are used to\n",
        "# make a action.\n",
        "model = QModel(num_actions)\n",
        "model.to('cuda')\n",
        "\n",
        "# Build a target model for the prediction of future rewards.\n",
        "# The weights of a target model get updated every 10000 steps thus when the\n",
        "# loss between the Q-values is calculated the target Q-value is stable.\n",
        "model_target = QModel(num_actions)\n",
        "model_target.to('cuda')\n",
        "\n",
        "loss_function = nn.SmoothL1Loss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.00025)"
      ],
      "metadata": {
        "id": "3u3lUayG0o7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experience replay buffers\n",
        "action_history = []\n",
        "state_history = []\n",
        "state_next_history = []\n",
        "rewards_history = []\n",
        "done_history = []\n",
        "episode_reward_history = []\n",
        "running_reward = 0\n",
        "episode_count = 0\n",
        "frame_count = 0\n",
        "\n",
        "# Number of frames to take random action and observe output\n",
        "epsilon_random_frames = 50000\n",
        "# Number of frames for exploration\n",
        "epsilon_greedy_frames = 100000.0\n",
        "# Maximum replay length\n",
        "# Note: The Deepmind paper suggests 1000000 however this causes memory issues\n",
        "max_memory_length = 500000\n",
        "# Train the model after 4 actions\n",
        "update_after_actions = 4\n",
        "# How often to update the target network\n",
        "update_target_network = 10000"
      ],
      "metadata": {
        "id": "3hGodqNc08rZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess = T.Compose([\n",
        "    T.ToPILImage(),\n",
        "    T.Grayscale(),\n",
        "    T.Resize((84, 84)),\n",
        "    T.ToTensor()\n",
        "])\n",
        "\n",
        "# Function to preprocess the state\n",
        "def preprocess_state(state):\n",
        "    state = preprocess(state).unsqueeze(0)\n",
        "    return state"
      ],
      "metadata": {
        "id": "-kZIWhM71Ns-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to select an action\n",
        "def get_greedy_epsilon(model, state):\n",
        "    global epsilon\n",
        "\n",
        "    #if frame_count < epsilon_random_frames or np.random.rand(1)[0] < epsilon:\n",
        "    if np.random.rand(1)[0] < epsilon:\n",
        "        action = np.random.randint(num_actions)\n",
        "    else:\n",
        "        with torch.no_grad():\n",
        "            # add a batch axis\n",
        "            #state = state.unsqueeze(0)\n",
        "            # compute the q-values\n",
        "            q_values = model(state)\n",
        "            # the action of maximum q-value\n",
        "            action = q_values.argmax().item()\n",
        "\n",
        "    # decay epsilon\n",
        "    epsilon -= epsilon_interval / epsilon_greedy_frames\n",
        "    epsilon = max(epsilon, epsilon_min)\n",
        "\n",
        "    return action"
      ],
      "metadata": {
        "id": "CPfiO0nZ09Yi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_greedy_action(model, state):\n",
        "    global epsilon\n",
        "\n",
        "    with torch.no_grad():\n",
        "        #state = state.unsqueeze(0) # batch dimension\n",
        "        q_values = model(state)\n",
        "        action = q_values.argmax().item()\n",
        "\n",
        "    return action"
      ],
      "metadata": {
        "id": "FVhhXbi92f3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sample a batch of _batch_size from replay buffers\n",
        "# return numpy.ndarrays\n",
        "def sample_batch(_batch_size):\n",
        "    # Get indices of samples for replay buffers\n",
        "    indices = np.random.choice(range(len(done_history)), size=_batch_size, replace=False)\n",
        "\n",
        "    state_sample = np.array([state_history[i].squeeze(0).numpy() for i in indices])\n",
        "    state_next_sample = np.array([state_next_history[i].squeeze(0).numpy() for i in indices])\n",
        "    rewards_sample = np.array([rewards_history[i] for i in indices], dtype=np.float32)\n",
        "    action_sample = np.array([action_history[i] for i in indices])\n",
        "    done_sample = np.array([float(done_history[i]) for i in indices])\n",
        "\n",
        "    return state_sample, state_next_sample, rewards_sample, action_sample, done_sample"
      ],
      "metadata": {
        "id": "3_9hivE42mlp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to update the Q-network\n",
        "def update_network():\n",
        "    # sample a batch of ...\n",
        "    state_sample, state_next_sample, rewards_sample, action_sample, done_sample = \\\n",
        "        sample_batch(batch_size)\n",
        "\n",
        "    # Convert numpy arrays to PyTorch tensors\n",
        "    state_sample = torch.tensor(state_sample, dtype=torch.float32).to('cuda')\n",
        "    state_next_sample = torch.tensor(state_next_sample, dtype=torch.float32).to('cuda')\n",
        "    action_sample = torch.tensor(action_sample, dtype=torch.int64).to('cuda')\n",
        "    rewards_sample = torch.tensor(rewards_sample, dtype=torch.float32).to('cuda')\n",
        "    done_sample = torch.tensor(done_sample, dtype=torch.float32).to('cuda')\n",
        "\n",
        "    # Compute the target Q-values for the states\n",
        "    with torch.no_grad():\n",
        "        future_rewards = model_target(state_next_sample)\n",
        "\n",
        "        # compute the q-value for the next state and the action maximizing the q-value\n",
        "        max_q_values = future_rewards.max(dim=1).values\n",
        "\n",
        "        # compute the target q-value\n",
        "        # if the step was final, max_q_values should not be added\n",
        "        target_q_values = rewards_sample + gamma * max_q_values * (1. - done_sample)\n",
        "\n",
        "    # It's forward propagation! Compute the Q-values for the taken actions\n",
        "    q_values = model(state_sample)\n",
        "    q_values_action = q_values.gather(dim=1, index=action_sample.unsqueeze(1)).squeeze(1)\n",
        "\n",
        "    # Compute the loss\n",
        "    loss = loss_function(q_values_action, target_q_values)\n",
        "\n",
        "    # Perform the optimization step\n",
        "    optimizer.zero_grad()#임시 변수를 0으로 초기화해두는것\n",
        "    loss.backward()# 역전파를 수행하며 기울기를 계산\n",
        "    optimizer.step() # +-기울기 업데이"
      ],
      "metadata": {
        "id": "067LMCDM2xDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:  # Run until solved\n",
        "    state, info = env.reset()\n",
        "    state, reward, done, _, info = env.step(1)\n",
        "    state = preprocess_state(state)\n",
        "    episode_reward = 0\n",
        "\n",
        "    for timestep in range(1, max_steps_per_episode):\n",
        "        frame_count += 1\n",
        "\n",
        "        # Select an action\n",
        "        action = get_greedy_epsilon(model, state.to('cuda'))\n",
        "\n",
        "        # Take the selected action\n",
        "        state_next, reward, done, _, info = env.step(action)\n",
        "        state_next = preprocess_state(state_next)\n",
        "\n",
        "        episode_reward += reward\n",
        "\n",
        "        # Store the transition in the replay buffer\n",
        "        action_history.append(action)\n",
        "        state_history.append(state)\n",
        "        state_next_history.append(state_next)\n",
        "        rewards_history.append(reward)\n",
        "        done_history.append(done)\n",
        "\n",
        "        state = state_next\n",
        "\n",
        "        # Update every fourth frame and once batch size is over 32\n",
        "        if frame_count % update_after_actions == 0 and len(done_history) > batch_size:\n",
        "            update_network()\n",
        "\n",
        "        if frame_count % update_target_network == 0:\n",
        "            model_target.load_state_dict(model.state_dict())\n",
        "\n",
        "        # Limit the state and reward history\n",
        "        if len(rewards_history) > max_memory_length:\n",
        "            del rewards_history[:1]\n",
        "            del state_history[:1]\n",
        "            del state_next_history[:1]\n",
        "            del action_history[:1]\n",
        "            del done_history[:1]\n",
        "\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    episode_count += 1\n",
        "    episode_reward_history.append(episode_reward)\n",
        "\n",
        "    # Update running reward to check condition for solving\n",
        "    if len(episode_reward_history) > 100:\n",
        "        del episode_reward_history[:1]\n",
        "    running_reward = np.mean(episode_reward_history)\n",
        "\n",
        "    if episode_count % 10 == 0:\n",
        "        print(f\"Episode: {episode_count}, Frame count: {frame_count}, Running reward: {running_reward}\")\n",
        "\n",
        "    if episode_count % 5000 == 0:\n",
        "        torch.save(model, 'model.{}'.format(episode_count))\n",
        "    if running_reward > 20:\n",
        "        print(f\"Solved at episode {episode_count}!\")\n",
        "        break\n",
        "    if episode_count % 10 == 0:\n",
        "        break\n",
        "\n",
        "\n",
        "torch.save(model, 'model.final')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgPMTl6F2_st",
        "outputId": "e694c369-3a7f-4da1-cf00-0d53e9bf03b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 10, Frame count: 6027, Running reward: 0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time, sys\n",
        "from IPython.display import clear_output\n",
        "from matplotlib import animation\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import imageio\n",
        "\n",
        "anim_file = 'atari.gif'\n",
        "\n",
        "turn =  0\n",
        "board, info = env.reset()\n",
        "state = preprocess_state(board)\n",
        "board, reward, done, _, info = env.step(1)\n",
        "state = preprocess_state(board)\n",
        "plt.imshow(board)\n",
        "plt.savefig('image_at_turn_{:04d}.png'.format(turn))\n",
        "\n",
        "for timestep in range(1, 50):\n",
        "    turn += 1\n",
        "    action = get_greedy_action(model, state.to('cuda'))\n",
        "    print(action)\n",
        "    board, reward, done, _, info = env.step(action)\n",
        "    state = preprocess_state(board)\n",
        "    plt.imshow(board)\n",
        "    plt.savefig('image_at_turn_{:04d}.png'.format(turn))\n",
        "\n",
        "    if done:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "s4lM71lH5FFz",
        "outputId": "cf7383a6-37ba-4453-bdf5-e457c353ff35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "2\n",
            "3\n",
            "0\n",
            "0\n",
            "1\n",
            "3\n",
            "1\n",
            "1\n",
            "3\n",
            "3\n",
            "1\n",
            "3\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "3\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "2\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aP7OauQk5eZs",
        "outputId": "55cd0bdc-ebdd-45bf-86e5-c92c0276ec37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image_at_turn_0000.png\timage_at_turn_0013.png\timage_at_turn_0026.png\timage_at_turn_0039.png\n",
            "image_at_turn_0001.png\timage_at_turn_0014.png\timage_at_turn_0027.png\timage_at_turn_0040.png\n",
            "image_at_turn_0002.png\timage_at_turn_0015.png\timage_at_turn_0028.png\timage_at_turn_0041.png\n",
            "image_at_turn_0003.png\timage_at_turn_0016.png\timage_at_turn_0029.png\timage_at_turn_0042.png\n",
            "image_at_turn_0004.png\timage_at_turn_0017.png\timage_at_turn_0030.png\timage_at_turn_0043.png\n",
            "image_at_turn_0005.png\timage_at_turn_0018.png\timage_at_turn_0031.png\timage_at_turn_0044.png\n",
            "image_at_turn_0006.png\timage_at_turn_0019.png\timage_at_turn_0032.png\timage_at_turn_0045.png\n",
            "image_at_turn_0007.png\timage_at_turn_0020.png\timage_at_turn_0033.png\timage_at_turn_0046.png\n",
            "image_at_turn_0008.png\timage_at_turn_0021.png\timage_at_turn_0034.png\timage_at_turn_0047.png\n",
            "image_at_turn_0009.png\timage_at_turn_0022.png\timage_at_turn_0035.png\timage_at_turn_0048.png\n",
            "image_at_turn_0010.png\timage_at_turn_0023.png\timage_at_turn_0036.png\timage_at_turn_0049.png\n",
            "image_at_turn_0011.png\timage_at_turn_0024.png\timage_at_turn_0037.png\tmodel.final\n",
            "image_at_turn_0012.png\timage_at_turn_0025.png\timage_at_turn_0038.png\tsample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generate animated gif file\n",
        "with imageio.get_writer(anim_file, mode='I') as writer:\n",
        "    filenames = glob.glob('image_at_turn_*.png')\n",
        "    filenames = sorted(filenames)\n",
        "    for filename in filenames:\n",
        "        print(filename)\n",
        "        image = imageio.imread(filename)\n",
        "        writer.append_data(image)\n",
        "    image = imageio.imread(filename)\n",
        "    writer.append_data(image)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4Wm0t1m5fa9",
        "outputId": "68317335-679b-463b-b0c8-03b3e78665f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image_at_turn_0000.png\n",
            "image_at_turn_0001.png\n",
            "image_at_turn_0002.png\n",
            "image_at_turn_0003.png\n",
            "image_at_turn_0004.png\n",
            "image_at_turn_0005.png\n",
            "image_at_turn_0006.png\n",
            "image_at_turn_0007.png\n",
            "image_at_turn_0008.png\n",
            "image_at_turn_0009.png\n",
            "image_at_turn_0010.png\n",
            "image_at_turn_0011.png\n",
            "image_at_turn_0012.png\n",
            "image_at_turn_0013.png\n",
            "image_at_turn_0014.png\n",
            "image_at_turn_0015.png\n",
            "image_at_turn_0016.png\n",
            "image_at_turn_0017.png\n",
            "image_at_turn_0018.png\n",
            "image_at_turn_0019.png\n",
            "image_at_turn_0020.png\n",
            "image_at_turn_0021.png\n",
            "image_at_turn_0022.png\n",
            "image_at_turn_0023.png\n",
            "image_at_turn_0024.png\n",
            "image_at_turn_0025.png\n",
            "image_at_turn_0026.png\n",
            "image_at_turn_0027.png\n",
            "image_at_turn_0028.png\n",
            "image_at_turn_0029.png\n",
            "image_at_turn_0030.png\n",
            "image_at_turn_0031.png\n",
            "image_at_turn_0032.png\n",
            "image_at_turn_0033.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-b17174db83f8>:7: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  image = imageio.imread(filename)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image_at_turn_0034.png\n",
            "image_at_turn_0035.png\n",
            "image_at_turn_0036.png\n",
            "image_at_turn_0037.png\n",
            "image_at_turn_0038.png\n",
            "image_at_turn_0039.png\n",
            "image_at_turn_0040.png\n",
            "image_at_turn_0041.png\n",
            "image_at_turn_0042.png\n",
            "image_at_turn_0043.png\n",
            "image_at_turn_0044.png\n",
            "image_at_turn_0045.png\n",
            "image_at_turn_0046.png\n",
            "image_at_turn_0047.png\n",
            "image_at_turn_0048.png\n",
            "image_at_turn_0049.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-b17174db83f8>:9: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  image = imageio.imread(filename)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnACjbHv5kii",
        "outputId": "7f70a903-3f00-4f74-e864-2198a0db0224"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "atari.gif\t\timage_at_turn_0013.png\timage_at_turn_0027.png\timage_at_turn_0041.png\n",
            "image_at_turn_0000.png\timage_at_turn_0014.png\timage_at_turn_0028.png\timage_at_turn_0042.png\n",
            "image_at_turn_0001.png\timage_at_turn_0015.png\timage_at_turn_0029.png\timage_at_turn_0043.png\n",
            "image_at_turn_0002.png\timage_at_turn_0016.png\timage_at_turn_0030.png\timage_at_turn_0044.png\n",
            "image_at_turn_0003.png\timage_at_turn_0017.png\timage_at_turn_0031.png\timage_at_turn_0045.png\n",
            "image_at_turn_0004.png\timage_at_turn_0018.png\timage_at_turn_0032.png\timage_at_turn_0046.png\n",
            "image_at_turn_0005.png\timage_at_turn_0019.png\timage_at_turn_0033.png\timage_at_turn_0047.png\n",
            "image_at_turn_0006.png\timage_at_turn_0020.png\timage_at_turn_0034.png\timage_at_turn_0048.png\n",
            "image_at_turn_0007.png\timage_at_turn_0021.png\timage_at_turn_0035.png\timage_at_turn_0049.png\n",
            "image_at_turn_0008.png\timage_at_turn_0022.png\timage_at_turn_0036.png\tmodel.final\n",
            "image_at_turn_0009.png\timage_at_turn_0023.png\timage_at_turn_0037.png\tsample_data\n",
            "image_at_turn_0010.png\timage_at_turn_0024.png\timage_at_turn_0038.png\n",
            "image_at_turn_0011.png\timage_at_turn_0025.png\timage_at_turn_0039.png\n",
            "image_at_turn_0012.png\timage_at_turn_0026.png\timage_at_turn_0040.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "Lq4nVgPe5ttQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aGtj3dn50Y3",
        "outputId": "e5fb65bc-d0bb-4b83-c1b8-f82be182bfb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp atari.gif drive/MyDrive/new.gif"
      ],
      "metadata": {
        "id": "sEAWU9lg54oG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import math\n",
        "x = Variable(\n",
        " torch.tensor(1., dtype=torch.float32),\n",
        " requires_grad=True)\n",
        "y = Variable(\n",
        " torch.tensor(1., dtype=torch.float32),\n",
        " requires_grad=True)\n",
        "z = Variable(\n",
        " torch.tensor(1., dtype=torch.float32),\n",
        " requires_grad=True)\n",
        "\n",
        "optimizer = torch.optim.SGD(params=[x, y], lr=0.01)\n",
        "\n",
        "EPOCHS = 100\n",
        "for epoch in range(EPOCHS):\n",
        "    f = 2*(x**2) + (y)**2 + (math.exp(4*x*y))\n",
        "    optimizer.zero_grad()\n",
        "    f.backward()\n",
        "    optimizer.step()\n",
        "print(x, y)\n",
        "print(f)"
      ],
      "metadata": {
        "id": "oeiD8oBN5-Oz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9178696f-f7cb-402a-8f28-0061c13dd9a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0169, requires_grad=True) tensor(0.1326, requires_grad=True)\n",
            "tensor(1.0285, grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "\n",
        "x = Variable(torch.tensor(1., dtype=torch.float32), requires_grad=True)\n",
        "y = Variable(torch.tensor(1., dtype=torch.float32), requires_grad=True)\n",
        "z = Variable(torch.tensor(1., dtype=torch.float32), requires_grad=True)\n",
        "\n",
        "optimizer = torch.optim.SGD(params=[x, y, z], lr=0.01)\n",
        "\n",
        "EPOCHS = 1000\n",
        "for epoch in range(EPOCHS):\n",
        "    f = 2*(x)**2 + y**2 + torch.exp(4*x*y)\n",
        "    optimizer.zero_grad()\n",
        "    f.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 100 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{EPOCHS}], x: {x.item():.4f}, y: {y.item():.4f}, f: {f.item():.4f}')\n",
        "\n",
        "print(f'Final values - x: {x.item():.4f}, y: {y.item():.4f}, f: {f.item():.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iqsCblVBYG7",
        "outputId": "c5b91a32-f033-4e8a-aaf3-994d7a44cde5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [100/1000], x: nan, y: nan, f: nan\n",
            "Epoch [200/1000], x: nan, y: nan, f: nan\n",
            "Epoch [300/1000], x: nan, y: nan, f: nan\n",
            "Epoch [400/1000], x: nan, y: nan, f: nan\n",
            "Epoch [500/1000], x: nan, y: nan, f: nan\n",
            "Epoch [600/1000], x: nan, y: nan, f: nan\n",
            "Epoch [700/1000], x: nan, y: nan, f: nan\n",
            "Epoch [800/1000], x: nan, y: nan, f: nan\n",
            "Epoch [900/1000], x: nan, y: nan, f: nan\n",
            "Epoch [1000/1000], x: nan, y: nan, f: nan\n",
            "Final values - x: nan, y: nan, f: nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "\n",
        "x = Variable(torch.tensor(1., dtype=torch.float32), requires_grad=True)\n",
        "y = Variable(torch.tensor(1., dtype=torch.float32), requires_grad=True)\n",
        "z = Variable(torch.tensor(1., dtype=torch.float32), requires_grad=True)\n",
        "\n",
        "optimizer = torch.optim.SGD(params=[x, y, z], lr=0.001)  # Reduced learning rate\n",
        "\n",
        "EPOCHS = 10000\n",
        "for epoch in range(EPOCHS):\n",
        "    f = 2*(x)**2 + y**2 + torch.exp(4*x*y)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    f.backward()\n",
        "\n",
        "    # Gradient Clipping\n",
        "    torch.nn.utils.clip_grad_norm_(parameters=[x, y, z], max_norm=1.0)  # Adjust max_norm as needed\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 100 == 0:\n",
        "        if torch.isnan(x).any() or torch.isnan(y).any() or torch.isnan(f).any():\n",
        "            print(f'Epoch [{epoch+1}/{EPOCHS}], NaN values encountered. Aborting.')\n",
        "            break\n",
        "        print(f'Epoch [{epoch+1}/{EPOCHS}], x: {x.item():.4f}, y: {y.item():.4f}, f: {f.item():.4f}')\n",
        "\n",
        "print(f'Final values - x: {x.item():.4f}, y: {y.item():.4f}, f: {f.item():.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sF8lbGhBvHe",
        "outputId": "9ac9ae11-dd7b-4b48-c38d-d0dd4ba254c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [100/10000], x: 0.9289, y: 0.9297, f: 34.3976\n",
            "Epoch [200/10000], x: 0.8574, y: 0.8598, f: 21.3864\n",
            "Epoch [300/10000], x: 0.7854, y: 0.7903, f: 13.8928\n",
            "Epoch [400/10000], x: 0.7128, y: 0.7216, f: 9.3976\n",
            "Epoch [500/10000], x: 0.6392, y: 0.6539, f: 6.5893\n",
            "Epoch [600/10000], x: 0.5644, y: 0.5875, f: 4.7646\n",
            "Epoch [700/10000], x: 0.4883, y: 0.5226, f: 3.5358\n",
            "Epoch [800/10000], x: 0.4108, y: 0.4595, f: 2.6834\n",
            "Epoch [900/10000], x: 0.3318, y: 0.3982, f: 2.0801\n",
            "Epoch [1000/10000], x: 0.2513, y: 0.3388, f: 1.6505\n",
            "Epoch [1100/10000], x: 0.1694, y: 0.2815, f: 1.3492\n",
            "Epoch [1200/10000], x: 0.0856, y: 0.2269, f: 1.1485\n",
            "Epoch [1300/10000], x: 0.0014, y: 0.1785, f: 1.0335\n",
            "Epoch [1400/10000], x: -0.0525, y: 0.1564, f: 0.9978\n",
            "Epoch [1500/10000], x: -0.0836, y: 0.1522, f: 0.9876\n",
            "Epoch [1600/10000], x: -0.1040, y: 0.1570, f: 0.9831\n",
            "Epoch [1700/10000], x: -0.1193, y: 0.1663, f: 0.9799\n",
            "Epoch [1800/10000], x: -0.1321, y: 0.1781, f: 0.9768\n",
            "Epoch [1900/10000], x: -0.1436, y: 0.1910, f: 0.9739\n",
            "Epoch [2000/10000], x: -0.1543, y: 0.2044, f: 0.9709\n",
            "Epoch [2100/10000], x: -0.1643, y: 0.2179, f: 0.9681\n",
            "Epoch [2200/10000], x: -0.1738, y: 0.2311, f: 0.9654\n",
            "Epoch [2300/10000], x: -0.1827, y: 0.2438, f: 0.9630\n",
            "Epoch [2400/10000], x: -0.1909, y: 0.2558, f: 0.9609\n",
            "Epoch [2500/10000], x: -0.1983, y: 0.2670, f: 0.9591\n",
            "Epoch [2600/10000], x: -0.2051, y: 0.2774, f: 0.9576\n",
            "Epoch [2700/10000], x: -0.2110, y: 0.2868, f: 0.9563\n",
            "Epoch [2800/10000], x: -0.2163, y: 0.2952, f: 0.9553\n",
            "Epoch [2900/10000], x: -0.2209, y: 0.3027, f: 0.9545\n",
            "Epoch [3000/10000], x: -0.2249, y: 0.3094, f: 0.9539\n",
            "Epoch [3100/10000], x: -0.2284, y: 0.3152, f: 0.9535\n",
            "Epoch [3200/10000], x: -0.2313, y: 0.3203, f: 0.9531\n",
            "Epoch [3300/10000], x: -0.2339, y: 0.3247, f: 0.9529\n",
            "Epoch [3400/10000], x: -0.2360, y: 0.3285, f: 0.9527\n",
            "Epoch [3500/10000], x: -0.2378, y: 0.3318, f: 0.9525\n",
            "Epoch [3600/10000], x: -0.2394, y: 0.3346, f: 0.9524\n",
            "Epoch [3700/10000], x: -0.2407, y: 0.3370, f: 0.9524\n",
            "Epoch [3800/10000], x: -0.2418, y: 0.3390, f: 0.9523\n",
            "Epoch [3900/10000], x: -0.2427, y: 0.3407, f: 0.9523\n",
            "Epoch [4000/10000], x: -0.2434, y: 0.3422, f: 0.9522\n",
            "Epoch [4100/10000], x: -0.2441, y: 0.3434, f: 0.9522\n",
            "Epoch [4200/10000], x: -0.2446, y: 0.3445, f: 0.9522\n",
            "Epoch [4300/10000], x: -0.2451, y: 0.3454, f: 0.9522\n",
            "Epoch [4400/10000], x: -0.2455, y: 0.3461, f: 0.9522\n",
            "Epoch [4500/10000], x: -0.2458, y: 0.3467, f: 0.9522\n",
            "Epoch [4600/10000], x: -0.2461, y: 0.3473, f: 0.9522\n",
            "Epoch [4700/10000], x: -0.2463, y: 0.3477, f: 0.9522\n",
            "Epoch [4800/10000], x: -0.2465, y: 0.3481, f: 0.9522\n",
            "Epoch [4900/10000], x: -0.2467, y: 0.3484, f: 0.9522\n",
            "Epoch [5000/10000], x: -0.2468, y: 0.3487, f: 0.9522\n",
            "Epoch [5100/10000], x: -0.2469, y: 0.3489, f: 0.9522\n",
            "Epoch [5200/10000], x: -0.2470, y: 0.3491, f: 0.9522\n",
            "Epoch [5300/10000], x: -0.2471, y: 0.3492, f: 0.9522\n",
            "Epoch [5400/10000], x: -0.2472, y: 0.3494, f: 0.9522\n",
            "Epoch [5500/10000], x: -0.2472, y: 0.3495, f: 0.9522\n",
            "Epoch [5600/10000], x: -0.2473, y: 0.3496, f: 0.9522\n",
            "Epoch [5700/10000], x: -0.2473, y: 0.3496, f: 0.9522\n",
            "Epoch [5800/10000], x: -0.2473, y: 0.3497, f: 0.9522\n",
            "Epoch [5900/10000], x: -0.2474, y: 0.3498, f: 0.9522\n",
            "Epoch [6000/10000], x: -0.2474, y: 0.3498, f: 0.9522\n",
            "Epoch [6100/10000], x: -0.2474, y: 0.3498, f: 0.9522\n",
            "Epoch [6200/10000], x: -0.2474, y: 0.3499, f: 0.9522\n",
            "Epoch [6300/10000], x: -0.2474, y: 0.3499, f: 0.9522\n",
            "Epoch [6400/10000], x: -0.2475, y: 0.3499, f: 0.9522\n",
            "Epoch [6500/10000], x: -0.2475, y: 0.3499, f: 0.9522\n",
            "Epoch [6600/10000], x: -0.2475, y: 0.3500, f: 0.9522\n",
            "Epoch [6700/10000], x: -0.2475, y: 0.3500, f: 0.9522\n",
            "Epoch [6800/10000], x: -0.2475, y: 0.3500, f: 0.9522\n",
            "Epoch [6900/10000], x: -0.2475, y: 0.3500, f: 0.9522\n",
            "Epoch [7000/10000], x: -0.2475, y: 0.3500, f: 0.9522\n",
            "Epoch [7100/10000], x: -0.2475, y: 0.3500, f: 0.9522\n",
            "Epoch [7200/10000], x: -0.2475, y: 0.3500, f: 0.9522\n",
            "Epoch [7300/10000], x: -0.2475, y: 0.3500, f: 0.9522\n",
            "Epoch [7400/10000], x: -0.2475, y: 0.3500, f: 0.9522\n",
            "Epoch [7500/10000], x: -0.2475, y: 0.3500, f: 0.9522\n",
            "Epoch [7600/10000], x: -0.2475, y: 0.3500, f: 0.9522\n",
            "Epoch [7700/10000], x: -0.2475, y: 0.3500, f: 0.9522\n",
            "Epoch [7800/10000], x: -0.2475, y: 0.3500, f: 0.9522\n",
            "Epoch [7900/10000], x: -0.2475, y: 0.3500, f: 0.9522\n",
            "Epoch [8000/10000], x: -0.2475, y: 0.3500, f: 0.9522\n",
            "Epoch [8100/10000], x: -0.2475, y: 0.3500, f: 0.9522\n",
            "Epoch [8200/10000], x: -0.2475, y: 0.3500, f: 0.9522\n",
            "Epoch [8300/10000], x: -0.2475, y: 0.3500, f: 0.9522\n",
            "Epoch [8400/10000], x: -0.2475, y: 0.3500, f: 0.9522\n",
            "Epoch [8500/10000], x: -0.2475, y: 0.3500, f: 0.9522\n",
            "Epoch [8600/10000], x: -0.2475, y: 0.3500, f: 0.9522\n",
            "Epoch [8700/10000], x: -0.2475, y: 0.3500, f: 0.9522\n",
            "Epoch [8800/10000], x: -0.2475, y: 0.3500, f: 0.9522\n",
            "Epoch [8900/10000], x: -0.2475, y: 0.3500, f: 0.9522\n",
            "Epoch [9000/10000], x: -0.2475, y: 0.3500, f: 0.9522\n",
            "Epoch [9100/10000], x: -0.2475, y: 0.3500, f: 0.9522\n",
            "Epoch [9200/10000], x: -0.2475, y: 0.3500, f: 0.9522\n",
            "Epoch [9300/10000], x: -0.2475, y: 0.3500, f: 0.9522\n",
            "Epoch [9400/10000], x: -0.2475, y: 0.3500, f: 0.9522\n",
            "Epoch [9500/10000], x: -0.2475, y: 0.3500, f: 0.9522\n",
            "Epoch [9600/10000], x: -0.2475, y: 0.3500, f: 0.9522\n",
            "Epoch [9700/10000], x: -0.2475, y: 0.3500, f: 0.9522\n",
            "Epoch [9800/10000], x: -0.2475, y: 0.3500, f: 0.9522\n",
            "Epoch [9900/10000], x: -0.2475, y: 0.3500, f: 0.9522\n",
            "Epoch [10000/10000], x: -0.2475, y: 0.3500, f: 0.9522\n",
            "Final values - x: -0.2475, y: 0.3500, f: 0.9522\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import math\n",
        "\n",
        "x = Variable(\n",
        " torch.tensor(1., dtype=torch.float32),\n",
        " requires_grad=True)\n",
        "y = Variable(\n",
        " torch.tensor(1., dtype=torch.float32),\n",
        " requires_grad=True)\n",
        "\n",
        "optimizer = torch.optim.SGD(params=[x, y, z], lr=0.01)\n",
        "\n",
        "EPOCHS = 1000\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "    f = (2*(x**2)) + y**2 + math.exp(4 * x * y)\n",
        "    # f = (x + y + z)**2 + (x-1)**2 + (y-1)**2 + (z-1)**2\n",
        "    optimizer.zero_grad()\n",
        "    f.backward()\n",
        "    optimizer.step()\n",
        "    print(f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCHW1-9xB6P2",
        "outputId": "47be4b5d-8ac0-4c34-fe4b-42d04e11b6ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(57.5981, grad_fn=<AddBackward0>)\n",
            "tensor(45.8897, grad_fn=<AddBackward0>)\n",
            "tensor(37.1024, grad_fn=<AddBackward0>)\n",
            "tensor(30.4128, grad_fn=<AddBackward0>)\n",
            "tensor(25.2510, grad_fn=<AddBackward0>)\n",
            "tensor(21.2170, grad_fn=<AddBackward0>)\n",
            "tensor(18.0263, grad_fn=<AddBackward0>)\n",
            "tensor(15.4739, grad_fn=<AddBackward0>)\n",
            "tensor(13.4102, grad_fn=<AddBackward0>)\n",
            "tensor(11.7247, grad_fn=<AddBackward0>)\n",
            "tensor(10.3350, grad_fn=<AddBackward0>)\n",
            "tensor(9.1791, grad_fn=<AddBackward0>)\n",
            "tensor(8.2095, grad_fn=<AddBackward0>)\n",
            "tensor(7.3899, grad_fn=<AddBackward0>)\n",
            "tensor(6.6919, grad_fn=<AddBackward0>)\n",
            "tensor(6.0935, grad_fn=<AddBackward0>)\n",
            "tensor(5.5772, grad_fn=<AddBackward0>)\n",
            "tensor(5.1290, grad_fn=<AddBackward0>)\n",
            "tensor(4.7378, grad_fn=<AddBackward0>)\n",
            "tensor(4.3945, grad_fn=<AddBackward0>)\n",
            "tensor(4.0919, grad_fn=<AddBackward0>)\n",
            "tensor(3.8239, grad_fn=<AddBackward0>)\n",
            "tensor(3.5856, grad_fn=<AddBackward0>)\n",
            "tensor(3.3728, grad_fn=<AddBackward0>)\n",
            "tensor(3.1821, grad_fn=<AddBackward0>)\n",
            "tensor(3.0107, grad_fn=<AddBackward0>)\n",
            "tensor(2.8561, grad_fn=<AddBackward0>)\n",
            "tensor(2.7163, grad_fn=<AddBackward0>)\n",
            "tensor(2.5894, grad_fn=<AddBackward0>)\n",
            "tensor(2.4741, grad_fn=<AddBackward0>)\n",
            "tensor(2.3690, grad_fn=<AddBackward0>)\n",
            "tensor(2.2729, grad_fn=<AddBackward0>)\n",
            "tensor(2.1850, grad_fn=<AddBackward0>)\n",
            "tensor(2.1044, grad_fn=<AddBackward0>)\n",
            "tensor(2.0303, grad_fn=<AddBackward0>)\n",
            "tensor(1.9621, grad_fn=<AddBackward0>)\n",
            "tensor(1.8992, grad_fn=<AddBackward0>)\n",
            "tensor(1.8411, grad_fn=<AddBackward0>)\n",
            "tensor(1.7874, grad_fn=<AddBackward0>)\n",
            "tensor(1.7377, grad_fn=<AddBackward0>)\n",
            "tensor(1.6916, grad_fn=<AddBackward0>)\n",
            "tensor(1.6489, grad_fn=<AddBackward0>)\n",
            "tensor(1.6091, grad_fn=<AddBackward0>)\n",
            "tensor(1.5722, grad_fn=<AddBackward0>)\n",
            "tensor(1.5378, grad_fn=<AddBackward0>)\n",
            "tensor(1.5057, grad_fn=<AddBackward0>)\n",
            "tensor(1.4758, grad_fn=<AddBackward0>)\n",
            "tensor(1.4479, grad_fn=<AddBackward0>)\n",
            "tensor(1.4218, grad_fn=<AddBackward0>)\n",
            "tensor(1.3975, grad_fn=<AddBackward0>)\n",
            "tensor(1.3746, grad_fn=<AddBackward0>)\n",
            "tensor(1.3533, grad_fn=<AddBackward0>)\n",
            "tensor(1.3333, grad_fn=<AddBackward0>)\n",
            "tensor(1.3145, grad_fn=<AddBackward0>)\n",
            "tensor(1.2969, grad_fn=<AddBackward0>)\n",
            "tensor(1.2804, grad_fn=<AddBackward0>)\n",
            "tensor(1.2649, grad_fn=<AddBackward0>)\n",
            "tensor(1.2504, grad_fn=<AddBackward0>)\n",
            "tensor(1.2367, grad_fn=<AddBackward0>)\n",
            "tensor(1.2238, grad_fn=<AddBackward0>)\n",
            "tensor(1.2117, grad_fn=<AddBackward0>)\n",
            "tensor(1.2003, grad_fn=<AddBackward0>)\n",
            "tensor(1.1896, grad_fn=<AddBackward0>)\n",
            "tensor(1.1795, grad_fn=<AddBackward0>)\n",
            "tensor(1.1699, grad_fn=<AddBackward0>)\n",
            "tensor(1.1610, grad_fn=<AddBackward0>)\n",
            "tensor(1.1525, grad_fn=<AddBackward0>)\n",
            "tensor(1.1445, grad_fn=<AddBackward0>)\n",
            "tensor(1.1370, grad_fn=<AddBackward0>)\n",
            "tensor(1.1298, grad_fn=<AddBackward0>)\n",
            "tensor(1.1231, grad_fn=<AddBackward0>)\n",
            "tensor(1.1168, grad_fn=<AddBackward0>)\n",
            "tensor(1.1108, grad_fn=<AddBackward0>)\n",
            "tensor(1.1051, grad_fn=<AddBackward0>)\n",
            "tensor(1.0998, grad_fn=<AddBackward0>)\n",
            "tensor(1.0947, grad_fn=<AddBackward0>)\n",
            "tensor(1.0899, grad_fn=<AddBackward0>)\n",
            "tensor(1.0854, grad_fn=<AddBackward0>)\n",
            "tensor(1.0811, grad_fn=<AddBackward0>)\n",
            "tensor(1.0770, grad_fn=<AddBackward0>)\n",
            "tensor(1.0732, grad_fn=<AddBackward0>)\n",
            "tensor(1.0695, grad_fn=<AddBackward0>)\n",
            "tensor(1.0661, grad_fn=<AddBackward0>)\n",
            "tensor(1.0628, grad_fn=<AddBackward0>)\n",
            "tensor(1.0597, grad_fn=<AddBackward0>)\n",
            "tensor(1.0568, grad_fn=<AddBackward0>)\n",
            "tensor(1.0540, grad_fn=<AddBackward0>)\n",
            "tensor(1.0514, grad_fn=<AddBackward0>)\n",
            "tensor(1.0489, grad_fn=<AddBackward0>)\n",
            "tensor(1.0465, grad_fn=<AddBackward0>)\n",
            "tensor(1.0442, grad_fn=<AddBackward0>)\n",
            "tensor(1.0421, grad_fn=<AddBackward0>)\n",
            "tensor(1.0401, grad_fn=<AddBackward0>)\n",
            "tensor(1.0382, grad_fn=<AddBackward0>)\n",
            "tensor(1.0363, grad_fn=<AddBackward0>)\n",
            "tensor(1.0346, grad_fn=<AddBackward0>)\n",
            "tensor(1.0330, grad_fn=<AddBackward0>)\n",
            "tensor(1.0314, grad_fn=<AddBackward0>)\n",
            "tensor(1.0299, grad_fn=<AddBackward0>)\n",
            "tensor(1.0285, grad_fn=<AddBackward0>)\n",
            "tensor(1.0271, grad_fn=<AddBackward0>)\n",
            "tensor(1.0259, grad_fn=<AddBackward0>)\n",
            "tensor(1.0247, grad_fn=<AddBackward0>)\n",
            "tensor(1.0235, grad_fn=<AddBackward0>)\n",
            "tensor(1.0224, grad_fn=<AddBackward0>)\n",
            "tensor(1.0214, grad_fn=<AddBackward0>)\n",
            "tensor(1.0204, grad_fn=<AddBackward0>)\n",
            "tensor(1.0194, grad_fn=<AddBackward0>)\n",
            "tensor(1.0185, grad_fn=<AddBackward0>)\n",
            "tensor(1.0177, grad_fn=<AddBackward0>)\n",
            "tensor(1.0169, grad_fn=<AddBackward0>)\n",
            "tensor(1.0161, grad_fn=<AddBackward0>)\n",
            "tensor(1.0154, grad_fn=<AddBackward0>)\n",
            "tensor(1.0147, grad_fn=<AddBackward0>)\n",
            "tensor(1.0140, grad_fn=<AddBackward0>)\n",
            "tensor(1.0134, grad_fn=<AddBackward0>)\n",
            "tensor(1.0127, grad_fn=<AddBackward0>)\n",
            "tensor(1.0122, grad_fn=<AddBackward0>)\n",
            "tensor(1.0116, grad_fn=<AddBackward0>)\n",
            "tensor(1.0111, grad_fn=<AddBackward0>)\n",
            "tensor(1.0106, grad_fn=<AddBackward0>)\n",
            "tensor(1.0101, grad_fn=<AddBackward0>)\n",
            "tensor(1.0097, grad_fn=<AddBackward0>)\n",
            "tensor(1.0092, grad_fn=<AddBackward0>)\n",
            "tensor(1.0088, grad_fn=<AddBackward0>)\n",
            "tensor(1.0084, grad_fn=<AddBackward0>)\n",
            "tensor(1.0081, grad_fn=<AddBackward0>)\n",
            "tensor(1.0077, grad_fn=<AddBackward0>)\n",
            "tensor(1.0074, grad_fn=<AddBackward0>)\n",
            "tensor(1.0070, grad_fn=<AddBackward0>)\n",
            "tensor(1.0067, grad_fn=<AddBackward0>)\n",
            "tensor(1.0064, grad_fn=<AddBackward0>)\n",
            "tensor(1.0061, grad_fn=<AddBackward0>)\n",
            "tensor(1.0059, grad_fn=<AddBackward0>)\n",
            "tensor(1.0056, grad_fn=<AddBackward0>)\n",
            "tensor(1.0054, grad_fn=<AddBackward0>)\n",
            "tensor(1.0051, grad_fn=<AddBackward0>)\n",
            "tensor(1.0049, grad_fn=<AddBackward0>)\n",
            "tensor(1.0047, grad_fn=<AddBackward0>)\n",
            "tensor(1.0045, grad_fn=<AddBackward0>)\n",
            "tensor(1.0043, grad_fn=<AddBackward0>)\n",
            "tensor(1.0041, grad_fn=<AddBackward0>)\n",
            "tensor(1.0039, grad_fn=<AddBackward0>)\n",
            "tensor(1.0038, grad_fn=<AddBackward0>)\n",
            "tensor(1.0036, grad_fn=<AddBackward0>)\n",
            "tensor(1.0034, grad_fn=<AddBackward0>)\n",
            "tensor(1.0033, grad_fn=<AddBackward0>)\n",
            "tensor(1.0032, grad_fn=<AddBackward0>)\n",
            "tensor(1.0030, grad_fn=<AddBackward0>)\n",
            "tensor(1.0029, grad_fn=<AddBackward0>)\n",
            "tensor(1.0028, grad_fn=<AddBackward0>)\n",
            "tensor(1.0026, grad_fn=<AddBackward0>)\n",
            "tensor(1.0025, grad_fn=<AddBackward0>)\n",
            "tensor(1.0024, grad_fn=<AddBackward0>)\n",
            "tensor(1.0023, grad_fn=<AddBackward0>)\n",
            "tensor(1.0022, grad_fn=<AddBackward0>)\n",
            "tensor(1.0021, grad_fn=<AddBackward0>)\n",
            "tensor(1.0020, grad_fn=<AddBackward0>)\n",
            "tensor(1.0020, grad_fn=<AddBackward0>)\n",
            "tensor(1.0019, grad_fn=<AddBackward0>)\n",
            "tensor(1.0018, grad_fn=<AddBackward0>)\n",
            "tensor(1.0017, grad_fn=<AddBackward0>)\n",
            "tensor(1.0016, grad_fn=<AddBackward0>)\n",
            "tensor(1.0016, grad_fn=<AddBackward0>)\n",
            "tensor(1.0015, grad_fn=<AddBackward0>)\n",
            "tensor(1.0014, grad_fn=<AddBackward0>)\n",
            "tensor(1.0014, grad_fn=<AddBackward0>)\n",
            "tensor(1.0013, grad_fn=<AddBackward0>)\n",
            "tensor(1.0013, grad_fn=<AddBackward0>)\n",
            "tensor(1.0012, grad_fn=<AddBackward0>)\n",
            "tensor(1.0012, grad_fn=<AddBackward0>)\n",
            "tensor(1.0011, grad_fn=<AddBackward0>)\n",
            "tensor(1.0011, grad_fn=<AddBackward0>)\n",
            "tensor(1.0010, grad_fn=<AddBackward0>)\n",
            "tensor(1.0010, grad_fn=<AddBackward0>)\n",
            "tensor(1.0009, grad_fn=<AddBackward0>)\n",
            "tensor(1.0009, grad_fn=<AddBackward0>)\n",
            "tensor(1.0009, grad_fn=<AddBackward0>)\n",
            "tensor(1.0008, grad_fn=<AddBackward0>)\n",
            "tensor(1.0008, grad_fn=<AddBackward0>)\n",
            "tensor(1.0008, grad_fn=<AddBackward0>)\n",
            "tensor(1.0007, grad_fn=<AddBackward0>)\n",
            "tensor(1.0007, grad_fn=<AddBackward0>)\n",
            "tensor(1.0007, grad_fn=<AddBackward0>)\n",
            "tensor(1.0006, grad_fn=<AddBackward0>)\n",
            "tensor(1.0006, grad_fn=<AddBackward0>)\n",
            "tensor(1.0006, grad_fn=<AddBackward0>)\n",
            "tensor(1.0006, grad_fn=<AddBackward0>)\n",
            "tensor(1.0005, grad_fn=<AddBackward0>)\n",
            "tensor(1.0005, grad_fn=<AddBackward0>)\n",
            "tensor(1.0005, grad_fn=<AddBackward0>)\n",
            "tensor(1.0005, grad_fn=<AddBackward0>)\n",
            "tensor(1.0005, grad_fn=<AddBackward0>)\n",
            "tensor(1.0004, grad_fn=<AddBackward0>)\n",
            "tensor(1.0004, grad_fn=<AddBackward0>)\n",
            "tensor(1.0004, grad_fn=<AddBackward0>)\n",
            "tensor(1.0004, grad_fn=<AddBackward0>)\n",
            "tensor(1.0004, grad_fn=<AddBackward0>)\n",
            "tensor(1.0004, grad_fn=<AddBackward0>)\n",
            "tensor(1.0003, grad_fn=<AddBackward0>)\n",
            "tensor(1.0003, grad_fn=<AddBackward0>)\n",
            "tensor(1.0003, grad_fn=<AddBackward0>)\n",
            "tensor(1.0003, grad_fn=<AddBackward0>)\n",
            "tensor(1.0003, grad_fn=<AddBackward0>)\n",
            "tensor(1.0003, grad_fn=<AddBackward0>)\n",
            "tensor(1.0003, grad_fn=<AddBackward0>)\n",
            "tensor(1.0003, grad_fn=<AddBackward0>)\n",
            "tensor(1.0002, grad_fn=<AddBackward0>)\n",
            "tensor(1.0002, grad_fn=<AddBackward0>)\n",
            "tensor(1.0002, grad_fn=<AddBackward0>)\n",
            "tensor(1.0002, grad_fn=<AddBackward0>)\n",
            "tensor(1.0002, grad_fn=<AddBackward0>)\n",
            "tensor(1.0002, grad_fn=<AddBackward0>)\n",
            "tensor(1.0002, grad_fn=<AddBackward0>)\n",
            "tensor(1.0002, grad_fn=<AddBackward0>)\n",
            "tensor(1.0002, grad_fn=<AddBackward0>)\n",
            "tensor(1.0002, grad_fn=<AddBackward0>)\n",
            "tensor(1.0002, grad_fn=<AddBackward0>)\n",
            "tensor(1.0002, grad_fn=<AddBackward0>)\n",
            "tensor(1.0001, grad_fn=<AddBackward0>)\n",
            "tensor(1.0001, grad_fn=<AddBackward0>)\n",
            "tensor(1.0001, grad_fn=<AddBackward0>)\n",
            "tensor(1.0001, grad_fn=<AddBackward0>)\n",
            "tensor(1.0001, grad_fn=<AddBackward0>)\n",
            "tensor(1.0001, grad_fn=<AddBackward0>)\n",
            "tensor(1.0001, grad_fn=<AddBackward0>)\n",
            "tensor(1.0001, grad_fn=<AddBackward0>)\n",
            "tensor(1.0001, grad_fn=<AddBackward0>)\n",
            "tensor(1.0001, grad_fn=<AddBackward0>)\n",
            "tensor(1.0001, grad_fn=<AddBackward0>)\n",
            "tensor(1.0001, grad_fn=<AddBackward0>)\n",
            "tensor(1.0001, grad_fn=<AddBackward0>)\n",
            "tensor(1.0001, grad_fn=<AddBackward0>)\n",
            "tensor(1.0001, grad_fn=<AddBackward0>)\n",
            "tensor(1.0001, grad_fn=<AddBackward0>)\n",
            "tensor(1.0001, grad_fn=<AddBackward0>)\n",
            "tensor(1.0001, grad_fn=<AddBackward0>)\n",
            "tensor(1.0001, grad_fn=<AddBackward0>)\n",
            "tensor(1.0001, grad_fn=<AddBackward0>)\n",
            "tensor(1.0001, grad_fn=<AddBackward0>)\n",
            "tensor(1.0001, grad_fn=<AddBackward0>)\n",
            "tensor(1.0001, grad_fn=<AddBackward0>)\n",
            "tensor(1.0001, grad_fn=<AddBackward0>)\n",
            "tensor(1.0001, grad_fn=<AddBackward0>)\n",
            "tensor(1.0001, grad_fn=<AddBackward0>)\n",
            "tensor(1.0001, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n",
            "tensor(1., grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "btA7fuvICDkm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}